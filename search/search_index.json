{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Swiss Territorial Data Lab (STDL) \u00b6 The STDL aims to promote collective innovation around the Swiss territory and its digital copy. It mainly explores the possibilities provided by data science to improve official land registering. A multidisciplinary team composed of cantonal, federal and academic partners is reinforced by engineers specialized in geodata science to tackle the challenges around the management of territorial datasets. The developed STDL platform codes and documentation are published under open licenses to allow partners and Swiss territory management actors to leverage the developed technologies. Tasks Reporting \u00b6 This section gives access to the documents pages giving the description of the ongoing and terminated tasks. Ongoing Tasks \u00b6 The following links provides access to the description of the current state of STDL ongoing tasks: TASK-DIFF : Automatic detection of changes in the environment TASK-IDET : Automatic analysis of geospatial images using deep learning including practical applications TASK-4RAS : Ingestion of raster data into the 4D platform The tasks are defined in the official STDL roadmap. Partnership and Collaborations \u00b6 The Partners of the STDL Board To contact the STDL, please use the following address: info@stdl.ch","title":"STDL Reporting"},{"location":"#swiss-territorial-data-lab-stdl","text":"The STDL aims to promote collective innovation around the Swiss territory and its digital copy. It mainly explores the possibilities provided by data science to improve official land registering. A multidisciplinary team composed of cantonal, federal and academic partners is reinforced by engineers specialized in geodata science to tackle the challenges around the management of territorial datasets. The developed STDL platform codes and documentation are published under open licenses to allow partners and Swiss territory management actors to leverage the developed technologies.","title":"Swiss Territorial Data Lab (STDL)"},{"location":"#tasks-reporting","text":"This section gives access to the documents pages giving the description of the ongoing and terminated tasks.","title":"Tasks Reporting"},{"location":"#ongoing-tasks","text":"The following links provides access to the description of the current state of STDL ongoing tasks: TASK-DIFF : Automatic detection of changes in the environment TASK-IDET : Automatic analysis of geospatial images using deep learning including practical applications TASK-4RAS : Ingestion of raster data into the 4D platform The tasks are defined in the official STDL roadmap.","title":"Ongoing Tasks"},{"location":"#partnership-and-collaborations","text":"The Partners of the STDL Board To contact the STDL, please use the following address: info@stdl.ch","title":"Partnership and Collaborations"},{"location":"TASK-4RAS/","text":"TASK-4RAS - HR, NH \u00b6 Schedule : September 2020 to February 2021 (initially planned from August 2021 February 2022) This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution Context \u00b6 The 4D platform developed at EPFL with the collaboration of Cadastre Suisse is able to ingest both large scale point-based and vector-based models. During the previous development, the possibility to have this different type of data in a single framework lead to interesting results, showing the interest to have the possibility to put this different type of data into perspectives. Illustrations of mixed models in the 4D platform : INTERLIS, Mesh and LIDAR - Data : SITN Taking into account point-based and vector-based model allows to almost cover all type of data that are traditionally considered for land registering. The only type of data that is currently missing is the two-dimensional rasters. Indeed, due to their nature, image are more complicated to put in perspective of other three-dimensional data. The goal of this task is then to address the management of the raster by the platform in order to be able to ingest, store and broadcast any type of data with the 4D platform. Specifications \u00b6 In order to address this task, a step-by-step approach is defined. In the first place, a set of data has to be gathered from the STDL partners : Gathering a dataset of geo-referenced ortho-photography of a chosen place of reasonable size The dataset has to provide ortho-photography for at least two different times The format of the dataset has to be analyzed in order to be able to extract the image pixels with their position (CH1903+) As the platform indexation formalism is not straightforward, the images are treated as point-based model, each pixel being one colored point of the model. This will allow to provide a way of starting to analyze and understand the indexation formalism while having first results on image integration : Transform images into simple point-based models (each pixel being one point) Injection of the point-based model in an experimental instance of the platform Understanding the indexation formalism for point-based models and, subsequently, its adaptation for the vector-based models As the indexation formalism is understood for point-based models, the following adaptation will be performed : removing the third dimension from the point-based indexation specifically for the image (flat indexation) At this point, a first reporting is required : Is there an advantage to add raster to such a platform in perspective of the other types of model (points, vectors, meshes) ? How the adaptation of the point-based indexation performs for images ? How taking advantage of color accumulation enrich the image integration ? What is the cost of rendering the image with the adaptation of the point-based indexation ? Based on the formulated answer, the following strategical choice has to be discussed : Would it be more efficient to integrate image keeping them as raster (deviation from the current indexation) ? Depending on the answer, a new set of specification will be decided (if this direction is favored). Depending on the remaining time and on the obtained results, the question of the time management in the platform will be addressed. Currently, the time is treated linearly in the platform and a multi-scale approach, as for the spatial dimensions, could be interesting. The specifications will be decided as the previous points will be fulfilled. Resources \u00b6 List of the resources initially linked to the task : liberatosthene - Platform and indexation back-end eratosthene-suite - Platform front-end Other resources will be provided according to requirements.","title":"TASK-4RAS"},{"location":"TASK-4RAS/#task-4ras-hr-nh","text":"Schedule : September 2020 to February 2021 (initially planned from August 2021 February 2022) This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution","title":"TASK-4RAS - HR, NH"},{"location":"TASK-4RAS/#context","text":"The 4D platform developed at EPFL with the collaboration of Cadastre Suisse is able to ingest both large scale point-based and vector-based models. During the previous development, the possibility to have this different type of data in a single framework lead to interesting results, showing the interest to have the possibility to put this different type of data into perspectives. Illustrations of mixed models in the 4D platform : INTERLIS, Mesh and LIDAR - Data : SITN Taking into account point-based and vector-based model allows to almost cover all type of data that are traditionally considered for land registering. The only type of data that is currently missing is the two-dimensional rasters. Indeed, due to their nature, image are more complicated to put in perspective of other three-dimensional data. The goal of this task is then to address the management of the raster by the platform in order to be able to ingest, store and broadcast any type of data with the 4D platform.","title":"Context"},{"location":"TASK-4RAS/#specifications","text":"In order to address this task, a step-by-step approach is defined. In the first place, a set of data has to be gathered from the STDL partners : Gathering a dataset of geo-referenced ortho-photography of a chosen place of reasonable size The dataset has to provide ortho-photography for at least two different times The format of the dataset has to be analyzed in order to be able to extract the image pixels with their position (CH1903+) As the platform indexation formalism is not straightforward, the images are treated as point-based model, each pixel being one colored point of the model. This will allow to provide a way of starting to analyze and understand the indexation formalism while having first results on image integration : Transform images into simple point-based models (each pixel being one point) Injection of the point-based model in an experimental instance of the platform Understanding the indexation formalism for point-based models and, subsequently, its adaptation for the vector-based models As the indexation formalism is understood for point-based models, the following adaptation will be performed : removing the third dimension from the point-based indexation specifically for the image (flat indexation) At this point, a first reporting is required : Is there an advantage to add raster to such a platform in perspective of the other types of model (points, vectors, meshes) ? How the adaptation of the point-based indexation performs for images ? How taking advantage of color accumulation enrich the image integration ? What is the cost of rendering the image with the adaptation of the point-based indexation ? Based on the formulated answer, the following strategical choice has to be discussed : Would it be more efficient to integrate image keeping them as raster (deviation from the current indexation) ? Depending on the answer, a new set of specification will be decided (if this direction is favored). Depending on the remaining time and on the obtained results, the question of the time management in the platform will be addressed. Currently, the time is treated linearly in the platform and a multi-scale approach, as for the spatial dimensions, could be interesting. The specifications will be decided as the previous points will be fulfilled.","title":"Specifications"},{"location":"TASK-4RAS/#resources","text":"List of the resources initially linked to the task : liberatosthene - Platform and indexation back-end eratosthene-suite - Platform front-end Other resources will be provided according to requirements.","title":"Resources"},{"location":"TASK-DIFF/","text":"TASK-DIFF - NH \u00b6 Schedule : September 2020 to February 2021 This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution Context \u00b6 Initially dedicated to handle large scale point-based models, the 4D platform developed at the DHLAB with the collaboration of Cadastre Suisse introduced an optimized Earth-attached indexation formalism. As the data access and broadcast performances were encouraging, it was decided to adapt the indexation formalism for vector-based models allowing the platform to ingest, store and broadcast any type of 3D data. In the context of differences detection and as the indexation formalism is based on equivalences classes defined on space and time, the space-time is naturally discretized along all of the four dimensions. This allowed to implements simple logical operators on the four-dimensional space. The OR, AND and XOR operators were then implemented allowing the platform to compute, on the fly, convolutions of models to compare one place at two different times. The implementation of theses operators was simple due to the natural spatiotemporal discretization obtained from the indexation formalism. Nevertheless, two major drawbacks appeared : the first one is that such operator only works for point-based models. Having the possibility to compute and render differences and similarities between any type of data is not possible with such formal operators. The second drawback comes from the nature of the point-based capturing devices. Indeed, taking the example of a building, even without any change to its structure, two digitization campaigns can lead to disparities only due to the point-based models sampling. The XOR operator is the natural choice to detect and render differences but this operator is very sensitive to sampling disparities. Computing the XOR convolution between two point-based models leads the rendering to be dominated by sampling variations rather than the desired structural differences. This drawback was partially solved by considering the AND operator. Indeed, the AND operator allows to only shows constant structural elements from two different positions in time and is insensitive to sampling disparities. As shown on the following images, the AND operator shows differences as black spots (lack of data) : AND convolution between two LIDAR models : Geneva 2005 and 2009 - Data : SITG As one can see, AND convolution allows to detect, through the black spots, large area of structural changes between the two times and also, with more care, allows to guess more small differences. The goal of this task is to tackle these two drawbacks allowing the platform to detect changes not only for point-based models but also for vector-based models and to show more clearly the differences between the compared to time positions. The task consists then in the implementation, testing and validation of disparity and similarity detection algorithms for any type of data taken at two different times and to conduct a formal analysis on the best detection and rendering techniques. Methodology \u00b6 A step by step methodology is defined to address the problem of differences and similarities detection in the platform. In a first phase, a first algorithm will be developed and validated on vector-based models as follows : Development of the algorithm on synthetic variations on a vector-based model Validation of the algorithm (using the known synthetic variations) First conclusion In a second phase, true land register data will be used to formally detect real evolution of the territory and to compare them with the land register databases : Obtaining true land register vector-based model (INTERLIS) at two different times Detecting the differences with the algorithm and validate them with the true land register revision In a third phase, the algorithm will be validated (and adapted) to work on point-based models : Obtaining true land register point-based model (LAS) at two different times Detecting the differences between the two times and validate them with the true land register revision Second conclusion Finally, in a last phase, both point-based and vector-based models will be considered without distinction to develop an algorithm able to compare any type of data between themselves based on the conclusion made during the first algorithm development : Detection of differences/similarities on different type of data : flat land register (vector) and 3D models (point, mesh) Analysis and conclusion on the results of the developed algorithm In addition, the development of differences and similarities algorithms has to be conducted keeping in mind the possible future evolution of the platform such as addition of layers (separation of data), implementation of a multi-scale approach of the time dimension and addition of raster data in the platform. First Phase : Synthetic Variations \u00b6 In order to implements the first vector-based differences detection algorithm, sets of data are considered as base on which synthetic differences are applied to simulate the evolution of the territory. This approach allows to focus on well controlled data to formally benchmark the results of the implemented algorithms. In addition, point-based models are also considered in order to determine in which extend the implemented vector-based differences detection algorithm can be operated on point clouds data with which results and performances. Selected Resources and Models \u00b6 Vector Models : Line-based \u00b6 In this first phase, line-based data are gathered from openstreetmap in order to create simple models used during the implementation and validation of the detection algorithms. A first set of vector-based models are considered made only of lines (land register). Three set are create each with a different scale, from cities to the whole Switzerland. The line-based sets of data are extracted from openstreetmap shapefiles and the elevation is restored using the SRTM geotiff data. The EGM96-5 geoid model is then used to convert the elevation from MSL to ellipsoid heights. The following images give an illustration of these sets of data : Line-based dataset : Switzerland (top), canton of Neuchatel (bottom left) and Frauenfeld city (bottom right) - Data : OSM In order to simulate evolution of the territory in time, synthetic variations are added to these models. A script is developed and used to insert controlled variations on selected primitives. The amount and the amplitude of these variations can also be controlled through the developed script. Vector Models : Triangle-based \u00b6 A second set of triangle-based models is also considered to implement and validate the differences detection algorithm. The selected model is a mesh model of the building of Geneva City. It comes aligned in the CH1903+ frame with the altitudes. It is simply converted into the WGS84 frame using again the EGM95-5 geoid model : Triangle-based dataset : Geneva buildings mesh - Data : SITG The developed script for line-based models is also used here to add synthetic variation to the model primitives in order to simulate an evolution of the territory. Point Models : LIDAR \u00b6 A third set of point-based models are considered to be able how the developed algorithm is able to provide results on such models. A selected portion of the city of Geneva LIDAR is considered as illustrated on the following image : Point-based dataset : Geneva LIDAR - Data : SITG In case of point-based models, taking into account the problem of sampling disparities that was experienced with the previously implemented XOR operator, two true case are here selected that are the LIDAR model in 2005 and 2009. This allows to apply the developed algorithm on real variations and to see how the sampling disparity is solved in case of such data. Implementation of the Algorithm \u00b6 In order to compare two models at two different positions in time to detect differences, the solution is of course to search for each primitive of the first time if it has a correspondence in the second time. In such case, the primitives can be concluded as static in time and only the primitives that have no correspondence will be highlighted as differences. A first approach was initially tested : a vertex-based comparison. As every primitive (points, lines and triangles) is supported by vertexes, it can be seen as a common denominator on which comparison can take place. Unfortunately, it is not a relevant approach as it leads to asymmetric detection algorithm. To illustrate the issue, the following image shows the situation of a group of primitives at two different times with an evolution on one of the primitive vertexes : Asymetric approach : the variation is detected only when comparing backward in time When the comparison occurs between the second time compared to the first one, the modified vertex is not found in the first model, and then, the vertex can be highlighted as a difference. The asymmetry appears as the first time is compared to the second one. In this case, despite the primitive vertex changed, the vertex-based approach is able to find another vertex, part of another static primitive, and interprets it as a vertex identity, leading the modified primitive to be considered as static. In order to obtain a fully symmetric algorithm, that does not depends on the way models are compared in times, a primitive based approach has to be considered. The implemented algorithm then treats the correspondence problem from the whole primitive point of view, by checking that the whole primitive can be found in the other model to which it is compared to. This allows to highlight any primitive showing a modification, regardless of the way models in time are compared. In addition to highlighting the primitives that changed through time, the implemented algorithm also keeps the primitive that did not changed. The ensemble of primitives are then shown by modulating their color to emphasize the modification by keeping their original color for modified one while the static primitives are shown in dark gray. This allows to not only show the modifications but also to keep the context of the modification helping the user to fully understand the nature of the territory evolution. Additional developments were required for triangle-based models : indeed, such models need to be subjected to a lighting model during rendering for the user to understand the model. As the differences are highlighted through color modulation, the implemented lighting model is causing difficulties to spot the highlighted primitives. The rendering client then checks for the differences detection algorithm and switches off the lighting in such case to make the differences more clear to the user. In addition, mesh models, as they are made of triangles, are hiding parts of themselves. It can then be difficult for the user to spot the highlighted primitives as they can be hidden by others. An option was added to the rendering client allowing the user to ask the rendering of triangles as line-loops or points in order to make them transparent. Experimentations and Results \u00b6 With the implemented algorithm, a series of experimentations are conducted in order to validate and analyze the performance of the differences detection algorithm for vector-based models. Differences Detection and Rendering \u00b6 With the implemented algorithms, it is possible to highlight any modification in the evolution of a model through time. The following image shows examples of modifications and how their are rendered for the user by the graphical client : Example of differences detection on Frauenfeld (left, two detections) and La Chaux-de-Fonds (right, one detection) - Data : OSM Right-click on the image and select \"View Image\" for full resolution Considering one of the two differences detected on the city of Frauenfeld, the following image shows the situation in the two compared models, at their respective position in time, that led to the detection : First model situation (left) compared the the second model situation (right) - Data : OSM Right-click on the image and select \"View Image\" for full resolution One can see that, despite the modification of the primitive vertex is very small and difficult to see, the algorithm is able to detect it and to show the user where to look for evolutions. On this example, the shown evolution of the primitive vertex is of the order of 10 centimeters, leading to a very difficult difference to spot without the help of the algorithm. Considering the triangle-based model, the following image shows how detected differences are rendered to the user : Example of differences detection on Geneva with filled (left) and line-loops (right) triangle rendering modes - Data : OSM Right-click on the image and select \"View Image\" for full resolution This shows how the differences detection algorithm is able to detect and render differences in a triangle-based model using the same color modulation technique as used for line-based models. One can see how rendering triangle as line-loops can ease the display of variations on triangle-based models allowing to see through the primitives. In case of point-based models, considering the true evolutions provided by the selected dataset, one can clearly see that, despite the algorithm is able to perfectly reflects modification in vector-based models, it is dominated by sampling disparities in such case : Example of differences detection on point-based data being dominated by sampling disparities - Data : SITG Right-click on the image and select \"View Image\" for full resolution One can see on the right image above that large amount of the building are highlighted as modification while the building did not shown any structural evolution between 2005 and 2009. This illustrates how sampling disparities can dominate the differences detection leading to complicated rendering for the user. The left image shows a larger view on which similar conclusion applies. The rendering is difficult to interpret for the user searching for territory evolutions. Nevertheless, it can be used as an educated guess to select area of changes. For example, the two following image illustrate how a large modification was discovered using the algorithm : Example of large territory evolution highlighted by the algorithm - Data : SITG Right-click on the image and select \"View Image\" for full resolution The following two images show the area structural situation in the 2005 and 2009 allowing to confirm the evolution of the territory : Structural situation of the detected evolution in 2005 (left) and 2009 (right) - Data : SITG Right-click on the image and select \"View Image\" for full resolution This specific example shows that large modifications of the territory can be detected on point-based models, but it also illustrates the limitations of the detection algorithm applied on such data. In order to detect the modification, the user must have some knowledge of what is a point cloud model and be aware of the effects of sampling disparities. Codes and Resources \u00b6 The following links gives you access to the codes related to this task : 4D platform main framework library 4D platform front-end including graphical client and server instance Shapefile CSV export to UV3 format conversion script UV3 related tool suite including display and conversion Auxiliary Developments & Corrections \u00b6 In addition to the main developments made on the platform, some other corrections have been made to solve minor problem or to improve the code according to the developed features during this task. The auxiliary developments are summarized here : Correction of socket read function to improve server-client connectivity Creation of scripts that allows to insert synthetic modifications (random displacements on the vertex coordinates) on UV3 models Creation of a script to convert CSV export from shapefile to UV3 format. The script code is available here Dynamical management of lighting during differences detection on triangle-based models Adding rendering option allowing the user to display triangles as filled triangles, line-loops or points to allow seeing through the primitive","title":"TASK-DIFF"},{"location":"TASK-DIFF/#task-diff-nh","text":"Schedule : September 2020 to February 2021 This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution","title":"TASK-DIFF - NH"},{"location":"TASK-DIFF/#context","text":"Initially dedicated to handle large scale point-based models, the 4D platform developed at the DHLAB with the collaboration of Cadastre Suisse introduced an optimized Earth-attached indexation formalism. As the data access and broadcast performances were encouraging, it was decided to adapt the indexation formalism for vector-based models allowing the platform to ingest, store and broadcast any type of 3D data. In the context of differences detection and as the indexation formalism is based on equivalences classes defined on space and time, the space-time is naturally discretized along all of the four dimensions. This allowed to implements simple logical operators on the four-dimensional space. The OR, AND and XOR operators were then implemented allowing the platform to compute, on the fly, convolutions of models to compare one place at two different times. The implementation of theses operators was simple due to the natural spatiotemporal discretization obtained from the indexation formalism. Nevertheless, two major drawbacks appeared : the first one is that such operator only works for point-based models. Having the possibility to compute and render differences and similarities between any type of data is not possible with such formal operators. The second drawback comes from the nature of the point-based capturing devices. Indeed, taking the example of a building, even without any change to its structure, two digitization campaigns can lead to disparities only due to the point-based models sampling. The XOR operator is the natural choice to detect and render differences but this operator is very sensitive to sampling disparities. Computing the XOR convolution between two point-based models leads the rendering to be dominated by sampling variations rather than the desired structural differences. This drawback was partially solved by considering the AND operator. Indeed, the AND operator allows to only shows constant structural elements from two different positions in time and is insensitive to sampling disparities. As shown on the following images, the AND operator shows differences as black spots (lack of data) : AND convolution between two LIDAR models : Geneva 2005 and 2009 - Data : SITG As one can see, AND convolution allows to detect, through the black spots, large area of structural changes between the two times and also, with more care, allows to guess more small differences. The goal of this task is to tackle these two drawbacks allowing the platform to detect changes not only for point-based models but also for vector-based models and to show more clearly the differences between the compared to time positions. The task consists then in the implementation, testing and validation of disparity and similarity detection algorithms for any type of data taken at two different times and to conduct a formal analysis on the best detection and rendering techniques.","title":"Context"},{"location":"TASK-DIFF/#methodology","text":"A step by step methodology is defined to address the problem of differences and similarities detection in the platform. In a first phase, a first algorithm will be developed and validated on vector-based models as follows : Development of the algorithm on synthetic variations on a vector-based model Validation of the algorithm (using the known synthetic variations) First conclusion In a second phase, true land register data will be used to formally detect real evolution of the territory and to compare them with the land register databases : Obtaining true land register vector-based model (INTERLIS) at two different times Detecting the differences with the algorithm and validate them with the true land register revision In a third phase, the algorithm will be validated (and adapted) to work on point-based models : Obtaining true land register point-based model (LAS) at two different times Detecting the differences between the two times and validate them with the true land register revision Second conclusion Finally, in a last phase, both point-based and vector-based models will be considered without distinction to develop an algorithm able to compare any type of data between themselves based on the conclusion made during the first algorithm development : Detection of differences/similarities on different type of data : flat land register (vector) and 3D models (point, mesh) Analysis and conclusion on the results of the developed algorithm In addition, the development of differences and similarities algorithms has to be conducted keeping in mind the possible future evolution of the platform such as addition of layers (separation of data), implementation of a multi-scale approach of the time dimension and addition of raster data in the platform.","title":"Methodology"},{"location":"TASK-DIFF/#first-phase-synthetic-variations","text":"In order to implements the first vector-based differences detection algorithm, sets of data are considered as base on which synthetic differences are applied to simulate the evolution of the territory. This approach allows to focus on well controlled data to formally benchmark the results of the implemented algorithms. In addition, point-based models are also considered in order to determine in which extend the implemented vector-based differences detection algorithm can be operated on point clouds data with which results and performances.","title":"First Phase : Synthetic Variations"},{"location":"TASK-DIFF/#selected-resources-and-models","text":"","title":"Selected Resources and Models"},{"location":"TASK-DIFF/#vector-models-line-based","text":"In this first phase, line-based data are gathered from openstreetmap in order to create simple models used during the implementation and validation of the detection algorithms. A first set of vector-based models are considered made only of lines (land register). Three set are create each with a different scale, from cities to the whole Switzerland. The line-based sets of data are extracted from openstreetmap shapefiles and the elevation is restored using the SRTM geotiff data. The EGM96-5 geoid model is then used to convert the elevation from MSL to ellipsoid heights. The following images give an illustration of these sets of data : Line-based dataset : Switzerland (top), canton of Neuchatel (bottom left) and Frauenfeld city (bottom right) - Data : OSM In order to simulate evolution of the territory in time, synthetic variations are added to these models. A script is developed and used to insert controlled variations on selected primitives. The amount and the amplitude of these variations can also be controlled through the developed script.","title":"Vector Models : Line-based"},{"location":"TASK-DIFF/#vector-models-triangle-based","text":"A second set of triangle-based models is also considered to implement and validate the differences detection algorithm. The selected model is a mesh model of the building of Geneva City. It comes aligned in the CH1903+ frame with the altitudes. It is simply converted into the WGS84 frame using again the EGM95-5 geoid model : Triangle-based dataset : Geneva buildings mesh - Data : SITG The developed script for line-based models is also used here to add synthetic variation to the model primitives in order to simulate an evolution of the territory.","title":"Vector Models : Triangle-based"},{"location":"TASK-DIFF/#point-models-lidar","text":"A third set of point-based models are considered to be able how the developed algorithm is able to provide results on such models. A selected portion of the city of Geneva LIDAR is considered as illustrated on the following image : Point-based dataset : Geneva LIDAR - Data : SITG In case of point-based models, taking into account the problem of sampling disparities that was experienced with the previously implemented XOR operator, two true case are here selected that are the LIDAR model in 2005 and 2009. This allows to apply the developed algorithm on real variations and to see how the sampling disparity is solved in case of such data.","title":"Point Models : LIDAR"},{"location":"TASK-DIFF/#implementation-of-the-algorithm","text":"In order to compare two models at two different positions in time to detect differences, the solution is of course to search for each primitive of the first time if it has a correspondence in the second time. In such case, the primitives can be concluded as static in time and only the primitives that have no correspondence will be highlighted as differences. A first approach was initially tested : a vertex-based comparison. As every primitive (points, lines and triangles) is supported by vertexes, it can be seen as a common denominator on which comparison can take place. Unfortunately, it is not a relevant approach as it leads to asymmetric detection algorithm. To illustrate the issue, the following image shows the situation of a group of primitives at two different times with an evolution on one of the primitive vertexes : Asymetric approach : the variation is detected only when comparing backward in time When the comparison occurs between the second time compared to the first one, the modified vertex is not found in the first model, and then, the vertex can be highlighted as a difference. The asymmetry appears as the first time is compared to the second one. In this case, despite the primitive vertex changed, the vertex-based approach is able to find another vertex, part of another static primitive, and interprets it as a vertex identity, leading the modified primitive to be considered as static. In order to obtain a fully symmetric algorithm, that does not depends on the way models are compared in times, a primitive based approach has to be considered. The implemented algorithm then treats the correspondence problem from the whole primitive point of view, by checking that the whole primitive can be found in the other model to which it is compared to. This allows to highlight any primitive showing a modification, regardless of the way models in time are compared. In addition to highlighting the primitives that changed through time, the implemented algorithm also keeps the primitive that did not changed. The ensemble of primitives are then shown by modulating their color to emphasize the modification by keeping their original color for modified one while the static primitives are shown in dark gray. This allows to not only show the modifications but also to keep the context of the modification helping the user to fully understand the nature of the territory evolution. Additional developments were required for triangle-based models : indeed, such models need to be subjected to a lighting model during rendering for the user to understand the model. As the differences are highlighted through color modulation, the implemented lighting model is causing difficulties to spot the highlighted primitives. The rendering client then checks for the differences detection algorithm and switches off the lighting in such case to make the differences more clear to the user. In addition, mesh models, as they are made of triangles, are hiding parts of themselves. It can then be difficult for the user to spot the highlighted primitives as they can be hidden by others. An option was added to the rendering client allowing the user to ask the rendering of triangles as line-loops or points in order to make them transparent.","title":"Implementation of the Algorithm"},{"location":"TASK-DIFF/#experimentations-and-results","text":"With the implemented algorithm, a series of experimentations are conducted in order to validate and analyze the performance of the differences detection algorithm for vector-based models.","title":"Experimentations and Results"},{"location":"TASK-DIFF/#differences-detection-and-rendering","text":"With the implemented algorithms, it is possible to highlight any modification in the evolution of a model through time. The following image shows examples of modifications and how their are rendered for the user by the graphical client : Example of differences detection on Frauenfeld (left, two detections) and La Chaux-de-Fonds (right, one detection) - Data : OSM Right-click on the image and select \"View Image\" for full resolution Considering one of the two differences detected on the city of Frauenfeld, the following image shows the situation in the two compared models, at their respective position in time, that led to the detection : First model situation (left) compared the the second model situation (right) - Data : OSM Right-click on the image and select \"View Image\" for full resolution One can see that, despite the modification of the primitive vertex is very small and difficult to see, the algorithm is able to detect it and to show the user where to look for evolutions. On this example, the shown evolution of the primitive vertex is of the order of 10 centimeters, leading to a very difficult difference to spot without the help of the algorithm. Considering the triangle-based model, the following image shows how detected differences are rendered to the user : Example of differences detection on Geneva with filled (left) and line-loops (right) triangle rendering modes - Data : OSM Right-click on the image and select \"View Image\" for full resolution This shows how the differences detection algorithm is able to detect and render differences in a triangle-based model using the same color modulation technique as used for line-based models. One can see how rendering triangle as line-loops can ease the display of variations on triangle-based models allowing to see through the primitives. In case of point-based models, considering the true evolutions provided by the selected dataset, one can clearly see that, despite the algorithm is able to perfectly reflects modification in vector-based models, it is dominated by sampling disparities in such case : Example of differences detection on point-based data being dominated by sampling disparities - Data : SITG Right-click on the image and select \"View Image\" for full resolution One can see on the right image above that large amount of the building are highlighted as modification while the building did not shown any structural evolution between 2005 and 2009. This illustrates how sampling disparities can dominate the differences detection leading to complicated rendering for the user. The left image shows a larger view on which similar conclusion applies. The rendering is difficult to interpret for the user searching for territory evolutions. Nevertheless, it can be used as an educated guess to select area of changes. For example, the two following image illustrate how a large modification was discovered using the algorithm : Example of large territory evolution highlighted by the algorithm - Data : SITG Right-click on the image and select \"View Image\" for full resolution The following two images show the area structural situation in the 2005 and 2009 allowing to confirm the evolution of the territory : Structural situation of the detected evolution in 2005 (left) and 2009 (right) - Data : SITG Right-click on the image and select \"View Image\" for full resolution This specific example shows that large modifications of the territory can be detected on point-based models, but it also illustrates the limitations of the detection algorithm applied on such data. In order to detect the modification, the user must have some knowledge of what is a point cloud model and be aware of the effects of sampling disparities.","title":"Differences Detection and Rendering"},{"location":"TASK-DIFF/#codes-and-resources","text":"The following links gives you access to the codes related to this task : 4D platform main framework library 4D platform front-end including graphical client and server instance Shapefile CSV export to UV3 format conversion script UV3 related tool suite including display and conversion","title":"Codes and Resources"},{"location":"TASK-DIFF/#auxiliary-developments-corrections","text":"In addition to the main developments made on the platform, some other corrections have been made to solve minor problem or to improve the code according to the developed features during this task. The auxiliary developments are summarized here : Correction of socket read function to improve server-client connectivity Creation of scripts that allows to insert synthetic modifications (random displacements on the vertex coordinates) on UV3 models Creation of a script to convert CSV export from shapefile to UV3 format. The script code is available here Dynamical management of lighting during differences detection on triangle-based models Adding rendering option allowing the user to display triangles as filled triangles, line-loops or points to allow seeing through the primitive","title":"Auxiliary Developments &amp; Corrections"},{"location":"TASK-IDET/","text":"TASK-IDET - AM & AC \u00b6 Current Mandate Schedule : October 2020 to September 2021 (with extension options until 2024) This document describes the state and roadmap of an ongoing task (Imagery Detections - IDET) and is subject to daily revision and evolution Objective \u00b6 This task of the STDL consists of the automated analysis of geospatial images (using deep learning) while providing practical applications for specific use cases. Background and Potential Use Cases \u00b6 Swimming Pool Detector \u00b6 Label inputs for deep learning derived from cadastral data Providing a reliable detection of swimming pools allows authorities to assess the status quo to update archival datasets and to reinforce administrative construction permit processes. The status quo is based on manually digitized cadastral information. This data is used to extract feature masks which can be applied to orthophoto imagery. Deep Learning algorithms such as Faster RCNN or Mask RCNN then allow the detection of previously unregistered swimming pools in a defined perimeter (such as the Canton of Geneva). Sol AI - Solar Panel Detector \u00b6 Sol AI is a prototypical framework solution developed by the Institute Geomatics of FHNW to provide location and geometry for millions of solar panel installations in Switzerland. We programmed a big data approach using parallelized multi gpu deep learning with Pytorch and additional post-classifiers on large scale 10cm SWISSIMAGE aerial imagery datasets by swisstopo. It is shown how we found a solution to extract geometries and energy potential and how to distinguish different solar panel types. Data handling, labelling strategies, geoconversions, read/write NoSQL interfaces, as well as deep learning training and inferencing results are described. Furthermore we show challenges, sample data, optimization strategies and focus on the computational demands the large amount of data imposes. Early Detection Result of a Resnet-50 Mask-RCNN architecture The Area Statistics \u00b6 The Area Statistics of Switzerland classifies land use (LU) and land cover (LC) based on a regular 100x100m grid of 4.2 million sample points in 72 categories combined from 46 LU and 27 LC classes. The arduous manual labelling process performed by experts relies mainly on aerial imagery but also uses a catalogue of additional data to increase reliability. The goal of this study is to investigate the benefits using multimodal data from different sources and sensors using modern machine learning (ML) algorithms. Deep Convolutional Neural Networks (CNN) as well as Random Forest (RF) architectures provide automatized classification. The models are trained on aerial RGB and FCIR images, as well as auxiliary datasets such as satellite-derived time series indices and GIS data. The accurate manually annotated Area Statistics serve as conducive \u201cground truth\u201d to study the performance of ML algorithms in a challenging paradigm in particular due to the high level of detail of the LU/LC categories. Especially for underrepresented categories containing low sample counts the benefits of transfer learning were exploited by applying the CNN architecture \u201cXception\u201d independently on 50x50m RGB and FCIR orthophoto tiles. Best preliminary classification accuracies of CNN reached over 80% on individual major classes, but maximal overall accuracies threshold to 52% due to tiles with visually very similar characteristics in different smaller ground truth classes. To further improve the classification, the resulting CNN probabilities were used together with extrapolated Landsat-based index time series, digital elevation data, vegetation canopy height models and categorical cadastral information as a combined input vector for RF post-classification. The RF achieved reproducible overall accuracies of 84% for LU and 89% for LC. Certain major classes, which so far required an especially monotonous manual process, are classified with very high specific accuracies (>90%). We conclude that multimodal data as provided by sensor fusion and auxiliary data sources in a bipartite system of ML algorithms has the potential to support the expert-based classification and reduce the manual work. Therefore, the reporting period can be significantly shortened and the spatial resolution can be further increased in future. Methodology \u00b6 Environments and Frameworks \u00b6 Google Colab Google Colab as a rapid prototyping environment High-Performance Cluster at FHNW HPE Apollo 6500 with 4 NVidia V100 GPUs Pytorch Detectron2 Tensorflow COCO Data Sources \u00b6 SWISSIMAGE RGB 10cm by swisstopo SWISSIMAGE RS 10cm by swisstopo Labels drawn from the official Swiss cadastral services. The Swiss cadastral system comprises the cadastral surveying, the Cadastre of Public-law Restrictions on landownership (PLR-cadastre) and the land register. Results \u00b6 Deep Learning Benchmarking Tests \u00b6 Swimming Pool Detector \u00b6 Masks vs. Bbox with Resnet-50 Mask RCNN Resnet-50 vs. Resnet-101 Tile Size Dependencies Multi-Class Detectors \u00b6 Combining Solar Detector and Swimming Pool Detector vs. Single Class Paradigms Base Technology \u00b6 Detectron2 / Pytorch vs. Tensorflow Outlook \u00b6 Ultimately, an automatized system for surface classification based on aerial imagery and additional data sources will be proposed that allows consistent differential surface segmentation as a basis for differential change analysis. Spatiotemporal data storage provides insight into current, historical and future territorial features scalabe from small communal objects to the environmental and landscape levels. Links and Resources \u00b6 Institute Geomatics FHNW Project Area Statistics Project Sol Ai Project Animal Detection Swisstopo BFS / OFS BFE / Energiestrategie 2050","title":"TASK-IDET"},{"location":"TASK-IDET/#task-idet-am-ac","text":"Current Mandate Schedule : October 2020 to September 2021 (with extension options until 2024) This document describes the state and roadmap of an ongoing task (Imagery Detections - IDET) and is subject to daily revision and evolution","title":"TASK-IDET - AM &amp; AC"},{"location":"TASK-IDET/#objective","text":"This task of the STDL consists of the automated analysis of geospatial images (using deep learning) while providing practical applications for specific use cases.","title":"Objective"},{"location":"TASK-IDET/#background-and-potential-use-cases","text":"","title":"Background and Potential Use Cases"},{"location":"TASK-IDET/#swimming-pool-detector","text":"Label inputs for deep learning derived from cadastral data Providing a reliable detection of swimming pools allows authorities to assess the status quo to update archival datasets and to reinforce administrative construction permit processes. The status quo is based on manually digitized cadastral information. This data is used to extract feature masks which can be applied to orthophoto imagery. Deep Learning algorithms such as Faster RCNN or Mask RCNN then allow the detection of previously unregistered swimming pools in a defined perimeter (such as the Canton of Geneva).","title":"Swimming Pool Detector"},{"location":"TASK-IDET/#sol-ai-solar-panel-detector","text":"Sol AI is a prototypical framework solution developed by the Institute Geomatics of FHNW to provide location and geometry for millions of solar panel installations in Switzerland. We programmed a big data approach using parallelized multi gpu deep learning with Pytorch and additional post-classifiers on large scale 10cm SWISSIMAGE aerial imagery datasets by swisstopo. It is shown how we found a solution to extract geometries and energy potential and how to distinguish different solar panel types. Data handling, labelling strategies, geoconversions, read/write NoSQL interfaces, as well as deep learning training and inferencing results are described. Furthermore we show challenges, sample data, optimization strategies and focus on the computational demands the large amount of data imposes. Early Detection Result of a Resnet-50 Mask-RCNN architecture","title":"Sol AI - Solar Panel Detector"},{"location":"TASK-IDET/#the-area-statistics","text":"The Area Statistics of Switzerland classifies land use (LU) and land cover (LC) based on a regular 100x100m grid of 4.2 million sample points in 72 categories combined from 46 LU and 27 LC classes. The arduous manual labelling process performed by experts relies mainly on aerial imagery but also uses a catalogue of additional data to increase reliability. The goal of this study is to investigate the benefits using multimodal data from different sources and sensors using modern machine learning (ML) algorithms. Deep Convolutional Neural Networks (CNN) as well as Random Forest (RF) architectures provide automatized classification. The models are trained on aerial RGB and FCIR images, as well as auxiliary datasets such as satellite-derived time series indices and GIS data. The accurate manually annotated Area Statistics serve as conducive \u201cground truth\u201d to study the performance of ML algorithms in a challenging paradigm in particular due to the high level of detail of the LU/LC categories. Especially for underrepresented categories containing low sample counts the benefits of transfer learning were exploited by applying the CNN architecture \u201cXception\u201d independently on 50x50m RGB and FCIR orthophoto tiles. Best preliminary classification accuracies of CNN reached over 80% on individual major classes, but maximal overall accuracies threshold to 52% due to tiles with visually very similar characteristics in different smaller ground truth classes. To further improve the classification, the resulting CNN probabilities were used together with extrapolated Landsat-based index time series, digital elevation data, vegetation canopy height models and categorical cadastral information as a combined input vector for RF post-classification. The RF achieved reproducible overall accuracies of 84% for LU and 89% for LC. Certain major classes, which so far required an especially monotonous manual process, are classified with very high specific accuracies (>90%). We conclude that multimodal data as provided by sensor fusion and auxiliary data sources in a bipartite system of ML algorithms has the potential to support the expert-based classification and reduce the manual work. Therefore, the reporting period can be significantly shortened and the spatial resolution can be further increased in future.","title":"The Area Statistics"},{"location":"TASK-IDET/#methodology","text":"","title":"Methodology"},{"location":"TASK-IDET/#environments-and-frameworks","text":"Google Colab Google Colab as a rapid prototyping environment High-Performance Cluster at FHNW HPE Apollo 6500 with 4 NVidia V100 GPUs Pytorch Detectron2 Tensorflow COCO","title":"Environments and Frameworks"},{"location":"TASK-IDET/#data-sources","text":"SWISSIMAGE RGB 10cm by swisstopo SWISSIMAGE RS 10cm by swisstopo Labels drawn from the official Swiss cadastral services. The Swiss cadastral system comprises the cadastral surveying, the Cadastre of Public-law Restrictions on landownership (PLR-cadastre) and the land register.","title":"Data Sources"},{"location":"TASK-IDET/#results","text":"","title":"Results"},{"location":"TASK-IDET/#deep-learning-benchmarking-tests","text":"","title":"Deep Learning Benchmarking Tests"},{"location":"TASK-IDET/#swimming-pool-detector_1","text":"Masks vs. Bbox with Resnet-50 Mask RCNN Resnet-50 vs. Resnet-101 Tile Size Dependencies","title":"Swimming Pool Detector"},{"location":"TASK-IDET/#multi-class-detectors","text":"Combining Solar Detector and Swimming Pool Detector vs. Single Class Paradigms","title":"Multi-Class Detectors"},{"location":"TASK-IDET/#base-technology","text":"Detectron2 / Pytorch vs. Tensorflow","title":"Base Technology"},{"location":"TASK-IDET/#outlook","text":"Ultimately, an automatized system for surface classification based on aerial imagery and additional data sources will be proposed that allows consistent differential surface segmentation as a basis for differential change analysis. Spatiotemporal data storage provides insight into current, historical and future territorial features scalabe from small communal objects to the environmental and landscape levels.","title":"Outlook"},{"location":"TASK-IDET/#links-and-resources","text":"Institute Geomatics FHNW Project Area Statistics Project Sol Ai Project Animal Detection Swisstopo BFS / OFS BFE / Energiestrategie 2050","title":"Links and Resources"}]}