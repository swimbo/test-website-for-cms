{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Swiss Territorial Data Lab (STDL) \u00b6 The STDL aims to promote collective innovation around the Swiss territory and its digital copy. It mainly explores the possibilities provided by data science to improve official land registering. A multidisciplinary team composed of cantonal, federal and academic partners is reinforced by engineers specialized in geographical data science to tackle the challenges around the management of territorial data-sets. The developed STDL platform codes and documentation are published under open licenses to allow partners and Swiss territory management actors to leverage the developed technologies. Tasks Reporting \u00b6 This section gives access to the documents pages giving the description of the ongoing and terminated tasks. A page is associated to each task reporting the ongoing and terminated work. Each pages comes with an introduction of the task goals and context. Ongoing Tasks \u00b6 The following links provides access to the description of the current state of STDL ongoing tasks: TASK-DIFF : Automatic detection of changes in the environment TASK-IDET : Automatic analysis of geospatial images using deep learning including practical applications TASK-4RAS : Ingestion of raster data into the 4D platform The tasks are defined in the official STDL road-map. Partnership and Collaborations \u00b6 The Partners of the STDL Board To contact the STDL, please use the following address: info@stdl.ch","title":"STDL Reporting"},{"location":"#swiss-territorial-data-lab-stdl","text":"The STDL aims to promote collective innovation around the Swiss territory and its digital copy. It mainly explores the possibilities provided by data science to improve official land registering. A multidisciplinary team composed of cantonal, federal and academic partners is reinforced by engineers specialized in geographical data science to tackle the challenges around the management of territorial data-sets. The developed STDL platform codes and documentation are published under open licenses to allow partners and Swiss territory management actors to leverage the developed technologies.","title":"Swiss Territorial Data Lab (STDL)"},{"location":"#tasks-reporting","text":"This section gives access to the documents pages giving the description of the ongoing and terminated tasks. A page is associated to each task reporting the ongoing and terminated work. Each pages comes with an introduction of the task goals and context.","title":"Tasks Reporting"},{"location":"#ongoing-tasks","text":"The following links provides access to the description of the current state of STDL ongoing tasks: TASK-DIFF : Automatic detection of changes in the environment TASK-IDET : Automatic analysis of geospatial images using deep learning including practical applications TASK-4RAS : Ingestion of raster data into the 4D platform The tasks are defined in the official STDL road-map.","title":"Ongoing Tasks"},{"location":"#partnership-and-collaborations","text":"The Partners of the STDL Board To contact the STDL, please use the following address: info@stdl.ch","title":"Partnership and Collaborations"},{"location":"TASK-4RAS/","text":"TASK-4RAS - HR, NH \u00b6 Schedule : September 2020 to February 2021 (initially planned from August 2021 February 2022) This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution Context \u00b6 The 4D platform developed at EPFL with the collaboration of Cadastre Suisse is able to ingest both large scale point-based and vector-based models. During the previous development, the possibility to have this different type of data in a single framework lead to interesting results, showing the interest to have the possibility to put this different type of data into perspectives. Illustrations of mixed models in the 4D platform : INTERLIS, Mesh and LIDAR - Data : SITN Taking into account point-based and vector-based model allows to almost cover all type of data that are traditionally considered for land registering. The only type of data that is currently missing is the two-dimensional rasters. Indeed, due to their nature, image are more complicated to put in perspective of other three-dimensional data. The goal of this task is then to address the management of the raster by the platform in order to be able to ingest, store and broadcast any type of data with the 4D platform. Specifications \u00b6 In order to address this task, a step-by-step approach is defined. In the first place, a set of data has to be gathered from the STDL partners : Gathering a dataset of geo-referenced ortho-photography of a chosen place of reasonable size The dataset has to provide ortho-photography for at least two different times The format of the dataset has to be analyzed in order to be able to extract the image pixels with their position (CH1903+) As the platform indexation formalism is not straightforward, the images are treated as point-based model, each pixel being one colored point of the model. This will allow to provide a way of starting to analyze and understand the indexation formalism while having first results on image integration : Transform images into simple point-based models (each pixel being one point) Injection of the point-based model in an experimental instance of the platform Understanding the indexation formalism for point-based models and, subsequently, its adaptation for the vector-based models As the indexation formalism is understood for point-based models, the following adaptation will be performed : removing the third dimension from the point-based indexation specifically for the image (flat indexation) At this point, a first reporting is required : Is there an advantage to add raster to such a platform in perspective of the other types of model (points, vectors, meshes) ? How the adaptation of the point-based indexation performs for images ? How taking advantage of color accumulation enrich the image integration ? What is the cost of rendering the image with the adaptation of the point-based indexation ? Based on the formulated answer, the following strategical choice has to be discussed : Would it be more efficient to integrate image keeping them as raster (deviation from the current indexation) ? Depending on the answer, a new set of specification will be decided (if this direction is favored). Depending on the remaining time and on the obtained results, the question of the time management in the platform will be addressed. Currently, the time is treated linearly in the platform and a multi-scale approach, as for the spatial dimensions, could be interesting. The specifications will be decided as the previous points will be fulfilled. Resources \u00b6 List of the resources initially linked to the task : liberatosthene - Platform and indexation back-end eratosthene-suite - Platform front-end Other resources will be provided according to requirements.","title":"TASK-4RAS"},{"location":"TASK-4RAS/#task-4ras-hr-nh","text":"Schedule : September 2020 to February 2021 (initially planned from August 2021 February 2022) This document describe the state of an ongoing task (DIFF) and is subject to daily revision and evolution","title":"TASK-4RAS - HR, NH"},{"location":"TASK-4RAS/#context","text":"The 4D platform developed at EPFL with the collaboration of Cadastre Suisse is able to ingest both large scale point-based and vector-based models. During the previous development, the possibility to have this different type of data in a single framework lead to interesting results, showing the interest to have the possibility to put this different type of data into perspectives. Illustrations of mixed models in the 4D platform : INTERLIS, Mesh and LIDAR - Data : SITN Taking into account point-based and vector-based model allows to almost cover all type of data that are traditionally considered for land registering. The only type of data that is currently missing is the two-dimensional rasters. Indeed, due to their nature, image are more complicated to put in perspective of other three-dimensional data. The goal of this task is then to address the management of the raster by the platform in order to be able to ingest, store and broadcast any type of data with the 4D platform.","title":"Context"},{"location":"TASK-4RAS/#specifications","text":"In order to address this task, a step-by-step approach is defined. In the first place, a set of data has to be gathered from the STDL partners : Gathering a dataset of geo-referenced ortho-photography of a chosen place of reasonable size The dataset has to provide ortho-photography for at least two different times The format of the dataset has to be analyzed in order to be able to extract the image pixels with their position (CH1903+) As the platform indexation formalism is not straightforward, the images are treated as point-based model, each pixel being one colored point of the model. This will allow to provide a way of starting to analyze and understand the indexation formalism while having first results on image integration : Transform images into simple point-based models (each pixel being one point) Injection of the point-based model in an experimental instance of the platform Understanding the indexation formalism for point-based models and, subsequently, its adaptation for the vector-based models As the indexation formalism is understood for point-based models, the following adaptation will be performed : removing the third dimension from the point-based indexation specifically for the image (flat indexation) At this point, a first reporting is required : Is there an advantage to add raster to such a platform in perspective of the other types of model (points, vectors, meshes) ? How the adaptation of the point-based indexation performs for images ? How taking advantage of color accumulation enrich the image integration ? What is the cost of rendering the image with the adaptation of the point-based indexation ? Based on the formulated answer, the following strategical choice has to be discussed : Would it be more efficient to integrate image keeping them as raster (deviation from the current indexation) ? Depending on the answer, a new set of specification will be decided (if this direction is favored). Depending on the remaining time and on the obtained results, the question of the time management in the platform will be addressed. Currently, the time is treated linearly in the platform and a multi-scale approach, as for the spatial dimensions, could be interesting. The specifications will be decided as the previous points will be fulfilled.","title":"Specifications"},{"location":"TASK-4RAS/#resources","text":"List of the resources initially linked to the task : liberatosthene - Platform and indexation back-end eratosthene-suite - Platform front-end Other resources will be provided according to requirements.","title":"Resources"},{"location":"TASK-DIFF/","text":"TASK-DIFF - NH \u00b6 Schedule : September 2020 to February 2021 This document describes the state of an ongoing task (DIFF) and is subject to daily revisions and evolutions Initially dedicated to handle large point-based models, the 4D platform, developed at the DHLAB with the collaboration of Cadastre Suisse, introduced an optimized 4D Earth-attached indexation formalism. As the data access and broadcast performances were encouraging, it was decided to adapt the indexation formalism for vector-based models allowing the platform to ingest, store and broadcast any type of 3D data associated with time. Task Context : Differences Detection \u00b6 As the implemented indexation formalism is based on equivalences classes defined on space and time, a natural discretization along all the four dimensions is obtained. In the direction of differences detection, it allowed implementing simple logical operators on the four-dimensional space. The OR , AND and XOR operators were then implemented allowing the platform to compute, on the fly, convolutions to compare models across the time. The implementation of these operators was simple due to the natural spatio-temporal discretization obtained from the indexation formalism. Nevertheless, two major drawbacks appeared : the first one is that such operators only works for point-based models. Having the opportunity to compute and render differences and similarities between any type of data is not possible with such formal operators. The second drawback comes from the nature of the point-based capturing devices. Indeed, taking the example of a building, even without any change to its structure, two digitization campaigns can lead to disparities only due to measures sampling. The XOR operator is the natural choice to detect and render differences, but this operator is very sensitive to sampling disparities. Computing the XOR convolution between two point-based models leads the rendering to be dominated by sampling variations rather than the desired structural differences. This drawback was partially solved by considering the AND operator. Indeed, the AND operator allows to only shows constant structural elements from two different positions in time and is insensitive to sampling disparities. As shown on the following images, the AND operator shows differences as black spots (missing parts) : AND convolution between two LIDAR models : Geneva 2005 and 2009 - Data : SITG As one can see, AND convolutions allows detecting, through the black spots, large area of structural changes between the two times and also, with more care, allows guessing smaller differences. The goal of this task is then to tackle these two drawbacks, allowing the platform to detect changes not only for point-based models but also for vector-based models and to implement a variation of the XOR operator for point-based models allowing to efficiently highlight the structural evolution . The task consists then in the implementation, testing and validation of a difference detection algorithm suitable for any type of model and to conduct a formal analysis on the best rendering techniques. Methodology \u00b6 A step by step methodology is defined to address the problem of differences detection in the platform. In a first phase, the algorithm will be developed and validated on vector-based models as follows : Development of the algorithm on synthetic variations using vector-based models Testing and validation of the algorithm (using the known synthetic variations) First conclusion In a second phase, true land register data will be used to formally detect real evolutions of the territory and to compare them with the land register databases : Obtaining true land register vector-based models (INTERLIS ) at two different times Detecting the differences with the algorithm and validate them with the true land register revisions Second conclusion In a third phase, the algorithm will be validated and adapted to work on point-based models : Obtaining true land register point-based models (LAS) at different position in time Verifying the performances of the vector-based detection algorithm on point-based data Adaptation of the algorithm for point-based models Third conclusion In addition, the development of differences detection algorithm has to be conducted keeping in mind the possible future evolutions of the platform such as addition of layers (separation of data), implementation of a multi-scale approach of the time dimension and addition of raster data in the platform. First Phase : Synthetic Variations \u00b6 In order to implements the vector-based differences detection algorithm, sets of data are considered as base on which synthetic differences are applied to simulate the evolution of the territory. This approach allows focusing on well controlled data to formally benchmark the results of the implemented algorithm. Experiments are conducted using these data to formally evaluate the performance of the developed algorithm. Selected Resources and Models \u00b6 Vector Models : Line-based \u00b6 In this first phase, line-based data are gathered from openstreetmap in order to create simple models used during the implementation and validation of the detection algorithm. A first set of vector-based models are considered made only of lines. Three sets are created each with a different scale, from city to the whole Switzerland. The line-based sets of data are extracted from openstreetmap shapefiles and the elevation is restored using the SRTM geotiff data. The EGM96-5 geoid model is then used to convert the elevation from MSL to ellipsoid heights. The following images give an illustration of these sets of data : Line-based data-sets : Switzerland (top), canton of Neuch\u00e2tel (bottom left) and Frauenfeld city (bottom right) - Data : OSM The following table gives a summary of the models sizes and primitives count : Model Size (UV3) Primitive Count Frauenfeld 5.0 Mio 93.3 K-Lines Neuch\u00e2tel 33.1 Mio 620.2 K-Lines Switzerland 1.3 Gio 25.0 M-Lines In order to simulate evolution of the territory in time, synthetic variations are added to these models. A script is developed and used to insert controlled variations on selected primitives. The script works by randomly selecting a user-defined amount of primitives of a model and adds a variation on one of its vertex position using a user-specified amplitude. The variation is applied on the three dimensions of space. Vector Models : Triangle-based \u00b6 A second set of triangle-based models is also considered to implement and validate the differences detection algorithm. The selected model is a mesh model of the Swiss buildings provided by SwissTopo. It comes aligned in the CH1903+ frame with elevations. It is simply converted into the WGS84 frame using again the EGM96-5 geoid model : Triangle-based data-sets : Switzerland (top), canton of Neuch\u00e2tel (bottom left) and Frauenfeld city (bottom right) - Data : SwissTopo The following table gives a summary of the models sizes and primitives count : Model Size (UV3) Primitive Count Frauenfeld 116.9 Mio 1.4 M-Triangles Neuch\u00e2tel 842.2 Mio 10.5 M-Triangles Switzerland 30.5 Gio 390.6 M-Triangles These models are very interesting for differences detection as the ratio between primitive size and model amplitude is very low. It means that all the primitive are small according to the coverage of the model, especially for the Switzerland one. The developed script for line-based models is also used here to add synthetic variations to the models primitives in order to simulate an evolution of the territory. Models : Statistical Analysis \u00b6 Before using the models in the following developments, a statistical analysis is performed on the two Switzerland models, line and triangle-based. Each primitive of these two models are considered and their edges size are computed to deduce their distribution : Statistical analysis : Models primitive edge size distribution, in meters, for the Switzerland models line-based (left) and triangle-based (right) One can see that the line-based model comes with much more broad distribution of the primitives size . Most of the model is made from lines between zero and twenty meters. In the case of the triangle-based models, the primitives are much smaller. As most of them are less than ten meters, a significant fraction of primitives is below one meter. Implementation of the Algorithm \u00b6 In order to compare two models at two different positions in time to detect differences, the solution is of course to search for each primitive of the primary time if it has a corresponding one in the secondary time. In such case, the primitives can be concluded as static in time and only the primitives that have no correspondence will be highlighted as differences. A first approach was initially tested : a vertex-based comparison. As every primitive (points, lines and triangles) is supported by vertexes, it can be seen as a common denominator on which comparison can take place. Unfortunately, it is not a relevant approach as it leads to an asymmetric detection algorithm. To illustrate the issue, the following image shows the situation of a group of line-based primitives at two different times with an evolution on one of the primitive vertex : Asymmetric approach : The variation is detected only when comparing backward in time When the comparison occurs between the second time and the first one, the modified vertex correspondence is not found, and the vertex can be highlighted as a difference. The asymmetry appears as the first time is compared to the second one. In this case, despite the primitive vertex changed, the vertex-based approach is able to find another vertex, part of another primitive, and interprets it as a vertex identity, leading the modified primitive to be considered as static. In order to obtain a fully symmetric algorithm, that does not depend on the way models are compared in times, a primitive-attached approach is considered. The implemented algorithm then treats the correspondence problem from the whole primitive point of view, by checking that the whole primitive can be found in the other model to which it is compared to. This allows to highlight any primitive showing a modification, regardless of the way models in time are compared and the nature of the modification. In addition to highlighting the primitives that changed through time, the implemented algorithm also keeps the primitives that have not changed. The ensemble of primitives is then shown by modulating their color to emphasize the modifications by keeping their original color for modified one, while the static primitives are shown in dark gray. This allows to not only show the modifications but also to keep the context of the modifications, helping the user to fully understand the nature of the territory evolution. In addition to color modulation, a variation of differences rendering is analyzed. In addition to color modulation, a visual and artificial marker is added to ease their search. The visual marker is a simple line emanating from the primitive and goes straight up with a size of 512 meters. Such markers are introduced to ease the detection of small primitives that can be difficult to spot according to large point of views. Additional developments were required for triangle-based models : indeed, such models need to be subjected to a light source during rendering for the user to understand the model (face shading). The previously implemented lighting model is then modified to take into account color modulation in order to correctly render the triangle that are highlighted. Moreover, the lighting model was modified to light both face of the triangles in order to light them regardless of the point of view. In addition, as mesh models are made of triangles, primitives can hide themselves. It can then be difficult for the user to spot the highlighted primitives as they can be hidden by others. An option was added to the rendering client allowing the user to ask the rendering of triangles as line-loops or points in order to make them transparent. Finally, an option allowing the user to enable or disable the render face culling was added for him to be able to see the primitive from backward. Results and Experiments \u00b6 With the implemented algorithm, a series of experiments are conducted in order to validate its results and to analyze the efficiency of the differences detection and rendering from a user point of view. In addition, experiments are also conducted to quantify the efficiency of the differences detection for automated processes. Differences Detection : Overview \u00b6 Considering the selected data-sets, each original model is injected at a given time and synthetic variations are added to a copy of it to create a second model injected at another time. The synthetic variations are randomly added to a small amount of primitives of the original model and are of the order of one meter. On the following examples, the detection is operated considering the original model as primary and the modified one as secondary. The following images show example of how the detection algorithm allows to highlight the detected differences while keeping the rest of the model using a darker color in case of line-based models : Example of differences detection on line-based Frauenfeld (left) and Neuch\u00e2tel (right) - Data : OSM Right-click on the image and select \"View Image\" for full resolution One can see how the modified primitives are highlighted while keeping the context of the modifications. The highlighted primitive is the one belonging to the primary time. Comparing the models in the other way around would lead the secondary model primitives to be highlighted. Considering the Frauenfeld example, the following images show the situation in the primary time (original model) and the secondary time (model with synthetic variations) : Primary model (left) and secondary one (right) showing the formal situation - The modified primitive is circled in read - Data : OSM Right-click on the image and select \"View Image\" for full resolution As a result, the user can choose between the differences highlighting with the choice of model as primary and can also switch back and worth between the models themselves though the platform interface. Of course, the readability of the difference detection models depends on the size of the modified primitive and the scale at which the model is looked at by the user. If the user adopts a large scale point of view, the differences, even highlighted, can become difficult to spot. This issue can be worsened as triangle-based models are considered. In addition to primitive size, triangle also bring occlusions. The visual markers added to the primitive highlighting can considerably improve ease of differences search by the user. The following images give an example of differences detection without and with the visual markers : Example of highlighted primitives without (left) and with (right) visual markers - Data : OSM Right-click on the image and select \"View Image\" for full resolution Considering the triangle-based models, differences detection is made more complicated by at least three aspects : the first one is that 3D vector models are more complex than 2D ones in the way primitives (triangles) are more densely packed in the same regions of space in order to correctly model the buildings. The second one is that triangles are solid primitives that bring occlusions in the rendering, hiding other primitives. The last aspects is that such model can contain very small primitives in order to model the details of the buildings. In such a case, the primitives can be difficult to see, even when highlighted. The following images show an example of highlighted triangles on the Frauenfeld model : Example of highlighted primitive on the Frauenfeld building model - Data : SwissTopo Right-click on the image and select \"View Image\" for full resolution On the right image above, the highlighted triangle is underneath the roof of the house, forcing the user to adopt an unconventional point of view (from above the house) to see it. In addition, some primitives can be defined fully inside a volume close by triangles, making them impossible to see without going inside the volume or playing with triangle rendering mode. In such a context, the usage of the visual markers become very important for such models coming with large amount of occlusion and small primitives : Example of highlighted primitives without (left) and with (right) visual markers - Data : SwissTopo Right-click on the image and select \"View Image\" for full resolution In case of triangle-based models, the usage of markers appears to be mandatory in order for the user to be able to locate the position of the detected differences in a reasonable amount of time. Differences Detection : User-Based Experiments \u00b6 In any case, for both line and triangle-based models, the differences detection algorithm is only able to highlight visible primitives. Depending on the point of view of the user, part of the primitives are not provided by the platform because of their small size. Indeed, the whole point of the platform is to allow the user to browse through arbitrary large models, which implies to provided only the relevant primitives according to its point of view. As a result, the detection algorithm will not be able to highlight the variations as the involved primitives are not considered. The user has then to reduce is point of view in order to zoom on the small primitives to make them appear, and so, allowing the algorithm to highlight them. In order to show this limitation, an experiment is performed. For each model, a copy is made on which eight synthetic differences are randomly introduced. The variations are of the order of one meter. The models and their modulated copy are injected in the platform. The rule is the following : the user uses the detection algorithm on each model and its modulated copy and has five minutes to detect the eight differences. Each time a difference is seen by the user, the detection time is kept. The user is allowed to use the platform in the way he wants. In each case, the experiment is repeated five times to get a mean detection rate. As one could ask, these measures are made by the user and are difficult to understand without a reference. In order to provide such reference, the following additional experiment is conducted : each model and its modulated copy are submitted to a naive automated detection process. This process parses each primitive of the original model to search in its modulated copy if the primitive appear. If the primitive is not found, the process trigger a difference detection. This process is called naive as its simply implements two nested loops, which is the simplest searching algorithm implementation. The process is written in C with full code optimization and executed on a single core. Starting with the line-based models, the following figures shows the differences detection rates according to time. For each of the three models, the left plots show the rate without visual markers, the middle ones with visual markers and the right ones the naive process detection rate : Frauenfeld : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Canton of Neuch\u00e2tel : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Switzerland : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process As expected, the larger the model is, the more difficult it is for the user to find the highlighted differences, with or without visual markers. Considering a city, the differences, even of the order of one meter, are quite easy to spot rapidly. As the model gets larger, the more time it takes for the user to find the differences. On a model covering a whole canton (Neuch\u00e2tel), one can see that most of the differences are detected in a reasonable amount of time despite their small size according to the overall model. On the Swiss model, things get more complicated, as simply looking at each part of the country is already complicated in only five minutes, leading the detection rate to be lower, even using the visual markers. These results are consistent with the statistical analysis made on the line-based Switzerland model. Detection on a city or even a whole canton lead the user to adopt a point of view sufficiently close to make most of the primitive appearing. For the Switzerland model, the user is forced to adopt a larger point of view, leading significant proportion of primitives to stay hidden. These results also show that adding visual markers to the highlighted primitives increases the user detection rate, meaning that the markers lead to a more suitable rendering from the user experience point of view. Considering the user results and the naive detection process, one can see that the user obtains at least similar results but most of the time outperforms the automated process. This allows to demonstrate how the implementation and data broadcasting strategy of the platform is able to provide an efficient way to access models and composite models, here in the context of differences detection. The following figures shows the experiments results for the triangle-based models : Frauenfeld : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Canton of Neuch\u00e2tel : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Edition Note (NH) : Missing triangle-based Switzerland model measures sessions. Similar conclusion applies for the triangle-based models : the larger the model is, the more difficult the differences detection is. These results also confirm that adding visual markers in addition to primitives highlighting significantly helps the user, particularly in case of triangle-based models. The obtained results on triangle-based models are lower than for line-based models. A first explanation is the greater amount of primitive that lead the user to spend more time at each successive point of view. The occlusion problem also seems to play a role, but to a lesser extent as the visual markers seems to largely solve it. The results differences have to be searched in the statistical analysis of the triangle-based models. Indeed, for these models, a large proportion of the primitives are very small (less than a meter), leading them to be rendered only as the user adopts a close point of view, making the detection much more complicated in such small amount of time. The triangle-based models being larger than the line-based one, the results of the naive process are very poor. As for the line-based models experiments, the user outperforms this automated process, in a much more significant way. Differences Detection : Process-Based Experiments \u00b6 In the previous experiments, the user ability to find the differences on the data-sets, using synthetic variations, was benchmark in perspective of the results provided by a naive automated process. The user performs quite well using the platform, but start to struggle as the data-sets get bigger according to the sizes of their primitives. In this second set of experiments, the platform is used through an automated process instead of a user. The process has the same task as the user, that is, finding the eight synthetic differences introduced in the models copy. The process starts with a list of index (the discretization cells of the platform) in order to query the corresponding data to the platform before to search for differences in each cell. The process implements, then, a systematic differences detection. In order for the process to work, it requires an input index list. To create it, the primitives injection condition of the platform is used to determine the maximal depth of these index. The following formula gives the poly-vertex (lines and triangles) primitives injection condition according to the platform scale. In other words, the formula gives the shallowest scale at which the primitive is considered through queries : where s gives the shallowest scale, R being the WGS84 major semi-axis and e is the largest distance, in meters, between the primitive first vertex and its other ones. For example, choosing s = 26 allows the index to reach any primitive that is greater than ~30 cm over the whole model covered by the index. The scale 26 is then chosen as the deepest search scale in the following experiments. This value can be adapted according to the primitives size and to the nature of the detection process. The larger it is, the more data are broadcast by the platform increasing the processing time. In order to compare the user-based experiments, the naive automated approach and this process-based exhaustive search, the same protocol is considered. The process addresses queries to the platform, based on the index list, and save the detection time of each difference. The detection rate is plot in the same way as for the used-based experiments. Again, eight synthetic differences are randomly introduced and the experiment is repeated five times for the line-based model and only two times for the triangle-based model. As the scale 26 is chosen as the deepest search scale, the index list can be built in different ways. Indeed, as a query is made of one spatial index, that points at the desired cell, and an additional depth (span), to specify the density of data, the only constraint to maintain the deepest search scale at 26 is the following : where the two left hand side terms are the spatial index size and span value. In these experiments, a first list of index is built using a span of 9 and a second with a span of 10 . As the deepest scale is maintained constant, increasing the span reduces the index list size, but the queried cells contain more data to analyze. The following figures show the mean detection rate for the Switzerland lined-based model with the deepest scale at 26 and span at 9 and 10 . The plots are scale in the same way as for the user-based experiments : Switzerland : The black curve shows the mean detection rate while the blue area gives the worst and best rates - Span at 9 (left) and 10 (right) Left : without visual markers - Middle : with visual markers - Right : automated process One can see that the detection rate on such a model is much better than the user-based or naive approach ones. In a manner of five minutes, for the span set to 10 , the eight differences can be detected and reported. The full detection process took ~5 minutes with span set to 10 and ~8 minutes with the span set to 9 . This shows how the platform is able to be used by automated processes as an efficient data provider. In addition, as the data are queried by the automated process, the detected primitives geometry is directly available, allowing all sorts of subsequent processes to take place. As the deepest scale was set to 26 , in one of the five measures session, one of the eight differences was not detected (at all). It means that the primitive on which a synthetic variation was introduced is smaller than 30cm and was then not reached by any index. This shows the importance of defining the spatial index and spans according to the processes needs. For example, increasing the deepest scale to 27 would allow reaching primitive down to ~15 cm over the whole Switzerland, and so on. The following figures show the mean detection rate for the Switzerland triangle-based model. In this case, only two measure sessions were made to limit the time spent on this analysis : Switzerland : The black curve shows the mean detection rate while the blue area gives the worst and best rates - Span at 9 (left) and 10 (right) Left : without visual markers - Middle : with visual markers - Right : automated process The conclusion remain, but the rate is slower in this case as the model contains much more primitives than the line-based one. In this case, the full detection process took ~15 minutes with span set to 10 and ~20 minutes with the span set to 9 . Again, in one of the two measure session, one difference was not detected due to the size of the primitive. Nevertheless, these results shows how the platform, seen as a process data provider, allows to outperform user-based and classic detection algorithms. Such process-based strategy can be performed in many ways depending on the needs. For example, the index list can be limited to a specific area or set to focus on spread and defined locations (for example at the intersection of the Swiss hectometric grid). The following image gives a simple example of how the detected differences can be leveraged. As the geometry of the differences is known by the process, a summary of the differences can be provided through a simple map : Example of a differences map based on the results of the detection process - Data : SRTM The eight synthetic differences are easily presented allowing a user to analyze them more in detail in the platform interface for example. This map was created detecting the eight differences on the line-based Switzerland model in about 5 minutes with a span set to 10 . Conclusion : First Phase \u00b6 During this first phase, the differences detection algorithm was built and validated on both line-based and triangle-based data. An efficient algorithm is then implemented in the platform allowing emphasizing differences between models at different temporal positions. The algorithm is able to perform the detection on the fly with good performances allowing the users to dynamically browse the data to detect and analyze the territory evolutions. The performances of the detection algorithm allow the platform to be suitable for automated detection processes, as a data provider, answering large amounts of queries in an efficient and remote manner. Two variations of the differences detection algorithm are implemented. The first version consists in highlighting the primitives that are subject to modifications over a time. This variation is suitable for automated process that can rely on simple search methods to list the differences. For the users, this first variation can lead to more difficult visual detection of the differences, especially in case the highlighted primitives are small or hidden by others. For this reason, visual markers were added on top of the highlighted primitives in order to be seen from far away, regardless of the primitives size. The measures sessions made during the user-based experiments showed a clear improvement of the detection rate when using the visual markers. This was especially true for triangle-based models, where the primitives bring occlusions. The user-based experiments showed that using the platform interface, a human can significantly outperform the result of a naive automated process operating on the models themselves. The experiments showed that the user is able to efficiently search and find through space and time the evolutions of the territory appearing in the data. Of course, as the model size and complexity increases, the user-driven interface starts to show its limits. In such a case, the process-based experiments showed that automated processes can take over these more complicated searches through methods allowing performing exhaustive detection over wide models in a matter of several minutes. At this point, the developments and validations of the algorithm, and its variations, were conducted on synthetic modifications introduced in models using controlled procedures. The next phase focuses on formal data extracted from land registers. Second Phase : True Variations \u00b6 Edition Note (NH) : Waiting for INTERLIS data. Conclusion : Second Phase \u00b6 Edition Note (NH) : Waiting for results. Third Phase : Point-Based Models \u00b6 In this third and last phase, the developed algorithm for differences detection on vector models is tested on point-based ones. As mentioned in the introduction, the platform was already implementing logical operators allowing comparing point-based models across time. As illustrated in the introduction, only the AND operator allowed emphasizing differences, but rendering them as missing part of the composite models. It was then difficult for the user to determine and analyze those differences. The goal of this last phase is to determine in which extend the developed algorithm is able to improve the initial results of point-based logical operators and how it can be adapted to provide better detection. Selected Resources and Models \u00b6 Point-Based Models : LIDAR \u00b6 Smaller data-sets are considered as point-based models are usually much larger. The city of Geneva is chosen as an example. Four identical chunks of LIDAR data are considered covering the railway station and its surroundings. The four models correspond to the digitization campaigns of 2005, 2009, 2013 and 2017. The data are converted from LAS to UV3 and brought to WGS84 using the EGM96-5 geoid model. The following images give an overview of the four selected models : Point-based data-sets : Geneva LIDAR of 2005 (top left), 2009 (top right), 2013 (bottom left) and 2017 (bottom right) - Data : SITG The following table gives a summary of the models sizes and primitive count : Model Size (UV3) Primitive Count Geneva 2005 663.2 Mio 24.8 M-Points Geneva 2009 1.2 Gio 46.7 M-Points Geneva 2013 3.9 Gio 4.2 G-Points Geneva 2017 7.0 Gio 7.5 G-Points The color of the models corresponds to the points classification. In addition, the models have a density that considerably increases with time, from 1 points/m^2 (2005) to 25 points/m^2 (2017). This disparity of density is considered as part of the sampling disparity, leading to a set of data very interesting to analyze and benchmark the differences detection algorithm. Models : Statistical Analysis \u00b6 As for line and triangle-based models, a statistical analysis of the point-based models is performed. The analysis consists in computing an approximation of the nearest neighbor distance distribution of points. The following figure shows the distribution of the 2005 and 2009 models : Statistical analysis : Nearest neighbor distribution approximation of the 2005 (left) and 2009 (right) models and the following figure shows the results for the 2013 and 2017 models : Statistical analysis : Nearest neighbor distribution approximation of the 2013 (left) and 2017 (right) models The nearest neighbor distribution tends to go toward zeros with the year of acquisition, showing that modern models are significantly denser that the older ones, making these data-sets interesting for the differences detection algorithm analysis. Differences Detection Algorithm : Direct Application on Point-Based Models \u00b6 In order to determine the performances of the differences detection algorithm on the selected point-based models, the algorithm is simply applied without any adaptation on the data-sets and the results are analyzed. The following images give an overview of the obtained results comparing the 2005 and 2009 models : Application of the differences detection algorithm on point-based models : Geneva model of 2005 and 2009 with 2005 as primary (left) and inversely (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution One can see that the obtained results are very similar to the results obtained with the previously implemented XOR logical operator. The only differences is that the identical points are shown (in dark gray) along with the highlighted points (showing the differences). The same conclusion applies : the obtained composed model is difficult to read as it is dominated by sampling disparities. One can, by carefully looking at the model, ending up detecting large modifications by searching for highlighted points accumulation. In addition, taking one model or the other as primary for the algorithm does not really help as shown on the images above. The same conclusion applies even when the two compared models comes with a similar point density as the 2013 and 2017 models : Application of the differences detection algorithm on point-based models : Geneva model of 2013 and 2017 with 2013 as primary (left) and inversely (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution One can nevertheless observe that choosing the less dense model as primary leads to results a bit more clear for differences detection, but remaining very hard to interpret for a user, and much more for automated processes. In addition, the performances of the algorithm are very poor as point-based models are much denser in terms of primitives than line or triangle-based models. These reasons lead to the conclusion that the algorithm can not be directly used for point-based models and need a more specific approach. Differences Detection Algorithm : Adaptation for Point-Based Models \u00b6 In order to adapt the differences detection algorithm for point-based models, two aspects have to be addressed : the efficiency of the detection (server-side) and the reduction of the sampling disparities over-representation. The problem of efficiency can be solved quite easily if the adaptation of the differences detection algorithm goes in the direction of logical operators, for which an efficient methodology is already implemented. Solving the sampling disparity over-representation is more complicated. The adopted solution is inspired from a simple observation : the less deep (density of cells) the queries are, the clearer the obtained representation is. This can be illustrated by the following images showing the 2005 model compared with the 2009 one with depth equal to 7, 6 and 5, from left to right : Example of decreasing query depth on the comparison of 2005 and 2009 models - Data SITG Right-click on the image and select \"View Image\" for full resolution This is expected, as the sampling disparities can only appear at scales corresponding to the nearest neighbor distribution. Nevertheless, as the depth is decreased, the models become less and less dense. The increase of differences readability is then compensated by the lack of density, making the structures more difficult to identify, and then, their subsequent modifications. The goal of the algorithm adaptation is to keep both readability and density. To achieve this goal, the implementation of the previous XOR operator is considered as a base, mostly for its efficiency. As the XOR simply detects if a cell of the space-time discretization at a given time is in a different state as its counterpart at another time, it can be modulated to introduce a scale delay mechanism that only applies detection on low-valued scales, broadcasting their results to their daughter cells. This allows to preserve the density and to perform the detection only on sufficiently shallow scales to avoid sampling disparities to become dominant. The question is how to operate the scale delay according to the scale itself. Indeed, with large points of view, the delay is not necessary as the model is viewed from far away. The necessity of the scale delay appears as the point of view is reduced, and, the more it is reduced, the larger the scale delay needs to be. A scale-attached delay is then defined to associate a specific value for each depth. Results and Experiments \u00b6 The adaptation of the differences detection algorithm for point-based models is analyzed using the selected data-sets. An overview of its result is presented before a more formal analysis is made using differences detection made on line-based official land register data. Differences Detection : Overview \u00b6 Considering the two first models, from 2005 and 2009 campaigns, the following images shows the results of the initial version of the differences detection algorithm (similar to XOR operator) and its adapted version implementing the scale delay : Differences detection on 2005 and 2009 models with 2005 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution One can see how __scale delay_ is able to drastically reduce the effect of sampling disparities while comparing two point-based models. The effect is more obvious as the 2009 model is set as primary for differences detection : Differences detection on 2005 and 2009 models with 2009 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution This improvement gets more clear as the point of view is reduced. The following image shows the initial algorithm and the scale delay algorithm on a specific area of the city with 2005 as primary model : Differences detection on 2005 and 2009 models with 2005 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution By inverting the model roles and making the 2009 model primary for differences detection lead to similar results : Differences detection on 2005 and 2009 models with 2009 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution Considering the denser models of 2013 and 2017 campaigns, the results of the scale delay introduction also lead to a better understanding of the differences as shown on the following images : Differences detection on 2013 and 2017 models with scale delay - Left : 2013 as primary - Right : 2017 as primary - Data SITG Right-click on the image and select \"View Image\" for full resolution Nevertheless, one can see that scale delay is not able to get rid entirely of sampling disparities. The right image above, comparing the 2017 model to the 2013 one, shows sampling disparities being highlighted as differences on the wall of the building in the background. This does not affect too much the user readability, but still make the model a bit more complicated to understand. In addition, the models play an important role in the way differences can be detected through classic approach. For example, focusing on a specific building, the obtained highlighted differences : Differences detection on 2013 and 2017 models with scale delay with 2013 (left) and 2017 (right) as primary - Data SITG Right-click on the image and select \"View Image\" for full resolution could lead the user to consider the building wall as a difference. Looking at the formal situation in both 2013 and 2017 models : Structural situation in 2013 (left) and 2017 (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution one can see that the detected difference comes from the missing wall on the 2013, and not from a formal evolution of the building. This example illustrates that sampling disparity is not the only factor that could reduce the readability of the model for the user. Differences Detection : Land Register Differences Comparison \u00b6 Edition Note (NH) : Waiting for INTERLIS data. Conclusion : Third Phase \u00b6 Edition Note (NH) : Waiting for results. Conclusion \u00b6 Edition Note (NH) : Waiting for results. First Phase \u00b6 Edition Note (NH) : Waiting for results. Second Phase \u00b6 Edition Note (NH) : Waiting for results. Third Phase \u00b6 Edition Note (NH) : Waiting for results. Synthesis \u00b6 Edition Note (NH) : Waiting for results. Perspectives \u00b6 Preliminary (NH) : Raster ingestion by the platform, opening new operators for data comparison Preliminary (NH) : Adding layers to the platform allowing to separate the data, toward more complex convolutions. Preliminary (NH) : Adding the notion of [Data Convolution Micro Language] in the platform allowing the user to build more complex convolutions with more than two source models (times). Preliminary (NH) : Attaching the platform indexation formalism to a [Swiss Box] to avoid necessity to convert all data from CH1903+/LV95 to WGS84/ellipsoidal frames. This would also allow improving communication efficiency between the server and its clients. In addition, it will also reduce the storage required by the platform and lead to a much better control of scales and cells size and shape consistency. Preliminary (NH) : Taking advantage of the differences detection algorithm on formal land register data [INTERLIS] to annotated image couples to train nets for differences detection on images and point clouds [Creation of dataset] Preliminary (NH) : The indexation, fixing the cell sizes, the poly-vertex primitive injection rules are not sufficiently clear for a simple understanding. It is required to simplify the rules in order to make automated processes more simple to fully control. This can be done with the reformulation of the indexation on the CH1903+/LV95 frame. Codes and Resources \u00b6 The following links give you access to the codes related to this task : 4D platform main framework library 4D platform front-end including graphical client and server instance Shapefile CSV export to UV3 format conversion script UV3 related tool suite including display and conversion Auxiliary Developments & Corrections \u00b6 In addition to the main developments made on the platform, some additional scripts and other corrections have been made to solve auxiliary problems or to improve the code according to the developed features during this task. The auxiliary developments are summarized here : Correction of socket read function to improve server-client connectivity. Creation of scripts that allows to insert synthetic modifications (random displacements on the vertex coordinates) on UV3 models. Creation of a script to convert CSV export from shapefile to UV3 format. The script code is available here . Adding temporary addresses (space-time index) exportation in platform 3D interface. Correction of the cell enumeration process in platform 3D interface (wrong depth limit implementation). Creation of a script allowing segmenting UV3 model according to geographical bounding box. Creation of C codes to perform statistical analysis of the point, line and triangle-based models : computation of edge size and nearest neighbor distributions. Creation of a C code allowing enumerating non-empty cell index over the Switzerland models injected in the platform. Creation of a C code allowing to automate the differences detection based on an index list and by searching in the data queried from the platform. Developments of various scripts for plots and figures creations.","title":"TASK-DIFF"},{"location":"TASK-DIFF/#task-diff-nh","text":"Schedule : September 2020 to February 2021 This document describes the state of an ongoing task (DIFF) and is subject to daily revisions and evolutions Initially dedicated to handle large point-based models, the 4D platform, developed at the DHLAB with the collaboration of Cadastre Suisse, introduced an optimized 4D Earth-attached indexation formalism. As the data access and broadcast performances were encouraging, it was decided to adapt the indexation formalism for vector-based models allowing the platform to ingest, store and broadcast any type of 3D data associated with time.","title":"TASK-DIFF - NH"},{"location":"TASK-DIFF/#task-context-differences-detection","text":"As the implemented indexation formalism is based on equivalences classes defined on space and time, a natural discretization along all the four dimensions is obtained. In the direction of differences detection, it allowed implementing simple logical operators on the four-dimensional space. The OR , AND and XOR operators were then implemented allowing the platform to compute, on the fly, convolutions to compare models across the time. The implementation of these operators was simple due to the natural spatio-temporal discretization obtained from the indexation formalism. Nevertheless, two major drawbacks appeared : the first one is that such operators only works for point-based models. Having the opportunity to compute and render differences and similarities between any type of data is not possible with such formal operators. The second drawback comes from the nature of the point-based capturing devices. Indeed, taking the example of a building, even without any change to its structure, two digitization campaigns can lead to disparities only due to measures sampling. The XOR operator is the natural choice to detect and render differences, but this operator is very sensitive to sampling disparities. Computing the XOR convolution between two point-based models leads the rendering to be dominated by sampling variations rather than the desired structural differences. This drawback was partially solved by considering the AND operator. Indeed, the AND operator allows to only shows constant structural elements from two different positions in time and is insensitive to sampling disparities. As shown on the following images, the AND operator shows differences as black spots (missing parts) : AND convolution between two LIDAR models : Geneva 2005 and 2009 - Data : SITG As one can see, AND convolutions allows detecting, through the black spots, large area of structural changes between the two times and also, with more care, allows guessing smaller differences. The goal of this task is then to tackle these two drawbacks, allowing the platform to detect changes not only for point-based models but also for vector-based models and to implement a variation of the XOR operator for point-based models allowing to efficiently highlight the structural evolution . The task consists then in the implementation, testing and validation of a difference detection algorithm suitable for any type of model and to conduct a formal analysis on the best rendering techniques.","title":"Task Context : Differences Detection"},{"location":"TASK-DIFF/#methodology","text":"A step by step methodology is defined to address the problem of differences detection in the platform. In a first phase, the algorithm will be developed and validated on vector-based models as follows : Development of the algorithm on synthetic variations using vector-based models Testing and validation of the algorithm (using the known synthetic variations) First conclusion In a second phase, true land register data will be used to formally detect real evolutions of the territory and to compare them with the land register databases : Obtaining true land register vector-based models (INTERLIS ) at two different times Detecting the differences with the algorithm and validate them with the true land register revisions Second conclusion In a third phase, the algorithm will be validated and adapted to work on point-based models : Obtaining true land register point-based models (LAS) at different position in time Verifying the performances of the vector-based detection algorithm on point-based data Adaptation of the algorithm for point-based models Third conclusion In addition, the development of differences detection algorithm has to be conducted keeping in mind the possible future evolutions of the platform such as addition of layers (separation of data), implementation of a multi-scale approach of the time dimension and addition of raster data in the platform.","title":"Methodology"},{"location":"TASK-DIFF/#first-phase-synthetic-variations","text":"In order to implements the vector-based differences detection algorithm, sets of data are considered as base on which synthetic differences are applied to simulate the evolution of the territory. This approach allows focusing on well controlled data to formally benchmark the results of the implemented algorithm. Experiments are conducted using these data to formally evaluate the performance of the developed algorithm.","title":"First Phase : Synthetic Variations"},{"location":"TASK-DIFF/#selected-resources-and-models","text":"","title":"Selected Resources and Models"},{"location":"TASK-DIFF/#vector-models-line-based","text":"In this first phase, line-based data are gathered from openstreetmap in order to create simple models used during the implementation and validation of the detection algorithm. A first set of vector-based models are considered made only of lines. Three sets are created each with a different scale, from city to the whole Switzerland. The line-based sets of data are extracted from openstreetmap shapefiles and the elevation is restored using the SRTM geotiff data. The EGM96-5 geoid model is then used to convert the elevation from MSL to ellipsoid heights. The following images give an illustration of these sets of data : Line-based data-sets : Switzerland (top), canton of Neuch\u00e2tel (bottom left) and Frauenfeld city (bottom right) - Data : OSM The following table gives a summary of the models sizes and primitives count : Model Size (UV3) Primitive Count Frauenfeld 5.0 Mio 93.3 K-Lines Neuch\u00e2tel 33.1 Mio 620.2 K-Lines Switzerland 1.3 Gio 25.0 M-Lines In order to simulate evolution of the territory in time, synthetic variations are added to these models. A script is developed and used to insert controlled variations on selected primitives. The script works by randomly selecting a user-defined amount of primitives of a model and adds a variation on one of its vertex position using a user-specified amplitude. The variation is applied on the three dimensions of space.","title":"Vector Models : Line-based"},{"location":"TASK-DIFF/#vector-models-triangle-based","text":"A second set of triangle-based models is also considered to implement and validate the differences detection algorithm. The selected model is a mesh model of the Swiss buildings provided by SwissTopo. It comes aligned in the CH1903+ frame with elevations. It is simply converted into the WGS84 frame using again the EGM96-5 geoid model : Triangle-based data-sets : Switzerland (top), canton of Neuch\u00e2tel (bottom left) and Frauenfeld city (bottom right) - Data : SwissTopo The following table gives a summary of the models sizes and primitives count : Model Size (UV3) Primitive Count Frauenfeld 116.9 Mio 1.4 M-Triangles Neuch\u00e2tel 842.2 Mio 10.5 M-Triangles Switzerland 30.5 Gio 390.6 M-Triangles These models are very interesting for differences detection as the ratio between primitive size and model amplitude is very low. It means that all the primitive are small according to the coverage of the model, especially for the Switzerland one. The developed script for line-based models is also used here to add synthetic variations to the models primitives in order to simulate an evolution of the territory.","title":"Vector Models : Triangle-based"},{"location":"TASK-DIFF/#models-statistical-analysis","text":"Before using the models in the following developments, a statistical analysis is performed on the two Switzerland models, line and triangle-based. Each primitive of these two models are considered and their edges size are computed to deduce their distribution : Statistical analysis : Models primitive edge size distribution, in meters, for the Switzerland models line-based (left) and triangle-based (right) One can see that the line-based model comes with much more broad distribution of the primitives size . Most of the model is made from lines between zero and twenty meters. In the case of the triangle-based models, the primitives are much smaller. As most of them are less than ten meters, a significant fraction of primitives is below one meter.","title":"Models : Statistical Analysis"},{"location":"TASK-DIFF/#implementation-of-the-algorithm","text":"In order to compare two models at two different positions in time to detect differences, the solution is of course to search for each primitive of the primary time if it has a corresponding one in the secondary time. In such case, the primitives can be concluded as static in time and only the primitives that have no correspondence will be highlighted as differences. A first approach was initially tested : a vertex-based comparison. As every primitive (points, lines and triangles) is supported by vertexes, it can be seen as a common denominator on which comparison can take place. Unfortunately, it is not a relevant approach as it leads to an asymmetric detection algorithm. To illustrate the issue, the following image shows the situation of a group of line-based primitives at two different times with an evolution on one of the primitive vertex : Asymmetric approach : The variation is detected only when comparing backward in time When the comparison occurs between the second time and the first one, the modified vertex correspondence is not found, and the vertex can be highlighted as a difference. The asymmetry appears as the first time is compared to the second one. In this case, despite the primitive vertex changed, the vertex-based approach is able to find another vertex, part of another primitive, and interprets it as a vertex identity, leading the modified primitive to be considered as static. In order to obtain a fully symmetric algorithm, that does not depend on the way models are compared in times, a primitive-attached approach is considered. The implemented algorithm then treats the correspondence problem from the whole primitive point of view, by checking that the whole primitive can be found in the other model to which it is compared to. This allows to highlight any primitive showing a modification, regardless of the way models in time are compared and the nature of the modification. In addition to highlighting the primitives that changed through time, the implemented algorithm also keeps the primitives that have not changed. The ensemble of primitives is then shown by modulating their color to emphasize the modifications by keeping their original color for modified one, while the static primitives are shown in dark gray. This allows to not only show the modifications but also to keep the context of the modifications, helping the user to fully understand the nature of the territory evolution. In addition to color modulation, a variation of differences rendering is analyzed. In addition to color modulation, a visual and artificial marker is added to ease their search. The visual marker is a simple line emanating from the primitive and goes straight up with a size of 512 meters. Such markers are introduced to ease the detection of small primitives that can be difficult to spot according to large point of views. Additional developments were required for triangle-based models : indeed, such models need to be subjected to a light source during rendering for the user to understand the model (face shading). The previously implemented lighting model is then modified to take into account color modulation in order to correctly render the triangle that are highlighted. Moreover, the lighting model was modified to light both face of the triangles in order to light them regardless of the point of view. In addition, as mesh models are made of triangles, primitives can hide themselves. It can then be difficult for the user to spot the highlighted primitives as they can be hidden by others. An option was added to the rendering client allowing the user to ask the rendering of triangles as line-loops or points in order to make them transparent. Finally, an option allowing the user to enable or disable the render face culling was added for him to be able to see the primitive from backward.","title":"Implementation of the Algorithm"},{"location":"TASK-DIFF/#results-and-experiments","text":"With the implemented algorithm, a series of experiments are conducted in order to validate its results and to analyze the efficiency of the differences detection and rendering from a user point of view. In addition, experiments are also conducted to quantify the efficiency of the differences detection for automated processes.","title":"Results and Experiments"},{"location":"TASK-DIFF/#differences-detection-overview","text":"Considering the selected data-sets, each original model is injected at a given time and synthetic variations are added to a copy of it to create a second model injected at another time. The synthetic variations are randomly added to a small amount of primitives of the original model and are of the order of one meter. On the following examples, the detection is operated considering the original model as primary and the modified one as secondary. The following images show example of how the detection algorithm allows to highlight the detected differences while keeping the rest of the model using a darker color in case of line-based models : Example of differences detection on line-based Frauenfeld (left) and Neuch\u00e2tel (right) - Data : OSM Right-click on the image and select \"View Image\" for full resolution One can see how the modified primitives are highlighted while keeping the context of the modifications. The highlighted primitive is the one belonging to the primary time. Comparing the models in the other way around would lead the secondary model primitives to be highlighted. Considering the Frauenfeld example, the following images show the situation in the primary time (original model) and the secondary time (model with synthetic variations) : Primary model (left) and secondary one (right) showing the formal situation - The modified primitive is circled in read - Data : OSM Right-click on the image and select \"View Image\" for full resolution As a result, the user can choose between the differences highlighting with the choice of model as primary and can also switch back and worth between the models themselves though the platform interface. Of course, the readability of the difference detection models depends on the size of the modified primitive and the scale at which the model is looked at by the user. If the user adopts a large scale point of view, the differences, even highlighted, can become difficult to spot. This issue can be worsened as triangle-based models are considered. In addition to primitive size, triangle also bring occlusions. The visual markers added to the primitive highlighting can considerably improve ease of differences search by the user. The following images give an example of differences detection without and with the visual markers : Example of highlighted primitives without (left) and with (right) visual markers - Data : OSM Right-click on the image and select \"View Image\" for full resolution Considering the triangle-based models, differences detection is made more complicated by at least three aspects : the first one is that 3D vector models are more complex than 2D ones in the way primitives (triangles) are more densely packed in the same regions of space in order to correctly model the buildings. The second one is that triangles are solid primitives that bring occlusions in the rendering, hiding other primitives. The last aspects is that such model can contain very small primitives in order to model the details of the buildings. In such a case, the primitives can be difficult to see, even when highlighted. The following images show an example of highlighted triangles on the Frauenfeld model : Example of highlighted primitive on the Frauenfeld building model - Data : SwissTopo Right-click on the image and select \"View Image\" for full resolution On the right image above, the highlighted triangle is underneath the roof of the house, forcing the user to adopt an unconventional point of view (from above the house) to see it. In addition, some primitives can be defined fully inside a volume close by triangles, making them impossible to see without going inside the volume or playing with triangle rendering mode. In such a context, the usage of the visual markers become very important for such models coming with large amount of occlusion and small primitives : Example of highlighted primitives without (left) and with (right) visual markers - Data : SwissTopo Right-click on the image and select \"View Image\" for full resolution In case of triangle-based models, the usage of markers appears to be mandatory in order for the user to be able to locate the position of the detected differences in a reasonable amount of time.","title":"Differences Detection : Overview"},{"location":"TASK-DIFF/#differences-detection-user-based-experiments","text":"In any case, for both line and triangle-based models, the differences detection algorithm is only able to highlight visible primitives. Depending on the point of view of the user, part of the primitives are not provided by the platform because of their small size. Indeed, the whole point of the platform is to allow the user to browse through arbitrary large models, which implies to provided only the relevant primitives according to its point of view. As a result, the detection algorithm will not be able to highlight the variations as the involved primitives are not considered. The user has then to reduce is point of view in order to zoom on the small primitives to make them appear, and so, allowing the algorithm to highlight them. In order to show this limitation, an experiment is performed. For each model, a copy is made on which eight synthetic differences are randomly introduced. The variations are of the order of one meter. The models and their modulated copy are injected in the platform. The rule is the following : the user uses the detection algorithm on each model and its modulated copy and has five minutes to detect the eight differences. Each time a difference is seen by the user, the detection time is kept. The user is allowed to use the platform in the way he wants. In each case, the experiment is repeated five times to get a mean detection rate. As one could ask, these measures are made by the user and are difficult to understand without a reference. In order to provide such reference, the following additional experiment is conducted : each model and its modulated copy are submitted to a naive automated detection process. This process parses each primitive of the original model to search in its modulated copy if the primitive appear. If the primitive is not found, the process trigger a difference detection. This process is called naive as its simply implements two nested loops, which is the simplest searching algorithm implementation. The process is written in C with full code optimization and executed on a single core. Starting with the line-based models, the following figures shows the differences detection rates according to time. For each of the three models, the left plots show the rate without visual markers, the middle ones with visual markers and the right ones the naive process detection rate : Frauenfeld : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Canton of Neuch\u00e2tel : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Switzerland : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process As expected, the larger the model is, the more difficult it is for the user to find the highlighted differences, with or without visual markers. Considering a city, the differences, even of the order of one meter, are quite easy to spot rapidly. As the model gets larger, the more time it takes for the user to find the differences. On a model covering a whole canton (Neuch\u00e2tel), one can see that most of the differences are detected in a reasonable amount of time despite their small size according to the overall model. On the Swiss model, things get more complicated, as simply looking at each part of the country is already complicated in only five minutes, leading the detection rate to be lower, even using the visual markers. These results are consistent with the statistical analysis made on the line-based Switzerland model. Detection on a city or even a whole canton lead the user to adopt a point of view sufficiently close to make most of the primitive appearing. For the Switzerland model, the user is forced to adopt a larger point of view, leading significant proportion of primitives to stay hidden. These results also show that adding visual markers to the highlighted primitives increases the user detection rate, meaning that the markers lead to a more suitable rendering from the user experience point of view. Considering the user results and the naive detection process, one can see that the user obtains at least similar results but most of the time outperforms the automated process. This allows to demonstrate how the implementation and data broadcasting strategy of the platform is able to provide an efficient way to access models and composite models, here in the context of differences detection. The following figures shows the experiments results for the triangle-based models : Frauenfeld : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Canton of Neuch\u00e2tel : The black curve shows the mean detection rate while the blue (left, middle) and red (right) area gives the worst and best rates Left : without visual markers - Middle : with visual markers - Right : automated process Edition Note (NH) : Missing triangle-based Switzerland model measures sessions. Similar conclusion applies for the triangle-based models : the larger the model is, the more difficult the differences detection is. These results also confirm that adding visual markers in addition to primitives highlighting significantly helps the user, particularly in case of triangle-based models. The obtained results on triangle-based models are lower than for line-based models. A first explanation is the greater amount of primitive that lead the user to spend more time at each successive point of view. The occlusion problem also seems to play a role, but to a lesser extent as the visual markers seems to largely solve it. The results differences have to be searched in the statistical analysis of the triangle-based models. Indeed, for these models, a large proportion of the primitives are very small (less than a meter), leading them to be rendered only as the user adopts a close point of view, making the detection much more complicated in such small amount of time. The triangle-based models being larger than the line-based one, the results of the naive process are very poor. As for the line-based models experiments, the user outperforms this automated process, in a much more significant way.","title":"Differences Detection : User-Based Experiments"},{"location":"TASK-DIFF/#differences-detection-process-based-experiments","text":"In the previous experiments, the user ability to find the differences on the data-sets, using synthetic variations, was benchmark in perspective of the results provided by a naive automated process. The user performs quite well using the platform, but start to struggle as the data-sets get bigger according to the sizes of their primitives. In this second set of experiments, the platform is used through an automated process instead of a user. The process has the same task as the user, that is, finding the eight synthetic differences introduced in the models copy. The process starts with a list of index (the discretization cells of the platform) in order to query the corresponding data to the platform before to search for differences in each cell. The process implements, then, a systematic differences detection. In order for the process to work, it requires an input index list. To create it, the primitives injection condition of the platform is used to determine the maximal depth of these index. The following formula gives the poly-vertex (lines and triangles) primitives injection condition according to the platform scale. In other words, the formula gives the shallowest scale at which the primitive is considered through queries : where s gives the shallowest scale, R being the WGS84 major semi-axis and e is the largest distance, in meters, between the primitive first vertex and its other ones. For example, choosing s = 26 allows the index to reach any primitive that is greater than ~30 cm over the whole model covered by the index. The scale 26 is then chosen as the deepest search scale in the following experiments. This value can be adapted according to the primitives size and to the nature of the detection process. The larger it is, the more data are broadcast by the platform increasing the processing time. In order to compare the user-based experiments, the naive automated approach and this process-based exhaustive search, the same protocol is considered. The process addresses queries to the platform, based on the index list, and save the detection time of each difference. The detection rate is plot in the same way as for the used-based experiments. Again, eight synthetic differences are randomly introduced and the experiment is repeated five times for the line-based model and only two times for the triangle-based model. As the scale 26 is chosen as the deepest search scale, the index list can be built in different ways. Indeed, as a query is made of one spatial index, that points at the desired cell, and an additional depth (span), to specify the density of data, the only constraint to maintain the deepest search scale at 26 is the following : where the two left hand side terms are the spatial index size and span value. In these experiments, a first list of index is built using a span of 9 and a second with a span of 10 . As the deepest scale is maintained constant, increasing the span reduces the index list size, but the queried cells contain more data to analyze. The following figures show the mean detection rate for the Switzerland lined-based model with the deepest scale at 26 and span at 9 and 10 . The plots are scale in the same way as for the user-based experiments : Switzerland : The black curve shows the mean detection rate while the blue area gives the worst and best rates - Span at 9 (left) and 10 (right) Left : without visual markers - Middle : with visual markers - Right : automated process One can see that the detection rate on such a model is much better than the user-based or naive approach ones. In a manner of five minutes, for the span set to 10 , the eight differences can be detected and reported. The full detection process took ~5 minutes with span set to 10 and ~8 minutes with the span set to 9 . This shows how the platform is able to be used by automated processes as an efficient data provider. In addition, as the data are queried by the automated process, the detected primitives geometry is directly available, allowing all sorts of subsequent processes to take place. As the deepest scale was set to 26 , in one of the five measures session, one of the eight differences was not detected (at all). It means that the primitive on which a synthetic variation was introduced is smaller than 30cm and was then not reached by any index. This shows the importance of defining the spatial index and spans according to the processes needs. For example, increasing the deepest scale to 27 would allow reaching primitive down to ~15 cm over the whole Switzerland, and so on. The following figures show the mean detection rate for the Switzerland triangle-based model. In this case, only two measure sessions were made to limit the time spent on this analysis : Switzerland : The black curve shows the mean detection rate while the blue area gives the worst and best rates - Span at 9 (left) and 10 (right) Left : without visual markers - Middle : with visual markers - Right : automated process The conclusion remain, but the rate is slower in this case as the model contains much more primitives than the line-based one. In this case, the full detection process took ~15 minutes with span set to 10 and ~20 minutes with the span set to 9 . Again, in one of the two measure session, one difference was not detected due to the size of the primitive. Nevertheless, these results shows how the platform, seen as a process data provider, allows to outperform user-based and classic detection algorithms. Such process-based strategy can be performed in many ways depending on the needs. For example, the index list can be limited to a specific area or set to focus on spread and defined locations (for example at the intersection of the Swiss hectometric grid). The following image gives a simple example of how the detected differences can be leveraged. As the geometry of the differences is known by the process, a summary of the differences can be provided through a simple map : Example of a differences map based on the results of the detection process - Data : SRTM The eight synthetic differences are easily presented allowing a user to analyze them more in detail in the platform interface for example. This map was created detecting the eight differences on the line-based Switzerland model in about 5 minutes with a span set to 10 .","title":"Differences Detection : Process-Based Experiments"},{"location":"TASK-DIFF/#conclusion-first-phase","text":"During this first phase, the differences detection algorithm was built and validated on both line-based and triangle-based data. An efficient algorithm is then implemented in the platform allowing emphasizing differences between models at different temporal positions. The algorithm is able to perform the detection on the fly with good performances allowing the users to dynamically browse the data to detect and analyze the territory evolutions. The performances of the detection algorithm allow the platform to be suitable for automated detection processes, as a data provider, answering large amounts of queries in an efficient and remote manner. Two variations of the differences detection algorithm are implemented. The first version consists in highlighting the primitives that are subject to modifications over a time. This variation is suitable for automated process that can rely on simple search methods to list the differences. For the users, this first variation can lead to more difficult visual detection of the differences, especially in case the highlighted primitives are small or hidden by others. For this reason, visual markers were added on top of the highlighted primitives in order to be seen from far away, regardless of the primitives size. The measures sessions made during the user-based experiments showed a clear improvement of the detection rate when using the visual markers. This was especially true for triangle-based models, where the primitives bring occlusions. The user-based experiments showed that using the platform interface, a human can significantly outperform the result of a naive automated process operating on the models themselves. The experiments showed that the user is able to efficiently search and find through space and time the evolutions of the territory appearing in the data. Of course, as the model size and complexity increases, the user-driven interface starts to show its limits. In such a case, the process-based experiments showed that automated processes can take over these more complicated searches through methods allowing performing exhaustive detection over wide models in a matter of several minutes. At this point, the developments and validations of the algorithm, and its variations, were conducted on synthetic modifications introduced in models using controlled procedures. The next phase focuses on formal data extracted from land registers.","title":"Conclusion : First Phase"},{"location":"TASK-DIFF/#second-phase-true-variations","text":"Edition Note (NH) : Waiting for INTERLIS data.","title":"Second Phase : True Variations"},{"location":"TASK-DIFF/#conclusion-second-phase","text":"Edition Note (NH) : Waiting for results.","title":"Conclusion : Second Phase"},{"location":"TASK-DIFF/#third-phase-point-based-models","text":"In this third and last phase, the developed algorithm for differences detection on vector models is tested on point-based ones. As mentioned in the introduction, the platform was already implementing logical operators allowing comparing point-based models across time. As illustrated in the introduction, only the AND operator allowed emphasizing differences, but rendering them as missing part of the composite models. It was then difficult for the user to determine and analyze those differences. The goal of this last phase is to determine in which extend the developed algorithm is able to improve the initial results of point-based logical operators and how it can be adapted to provide better detection.","title":"Third Phase : Point-Based Models"},{"location":"TASK-DIFF/#selected-resources-and-models_1","text":"","title":"Selected Resources and Models"},{"location":"TASK-DIFF/#point-based-models-lidar","text":"Smaller data-sets are considered as point-based models are usually much larger. The city of Geneva is chosen as an example. Four identical chunks of LIDAR data are considered covering the railway station and its surroundings. The four models correspond to the digitization campaigns of 2005, 2009, 2013 and 2017. The data are converted from LAS to UV3 and brought to WGS84 using the EGM96-5 geoid model. The following images give an overview of the four selected models : Point-based data-sets : Geneva LIDAR of 2005 (top left), 2009 (top right), 2013 (bottom left) and 2017 (bottom right) - Data : SITG The following table gives a summary of the models sizes and primitive count : Model Size (UV3) Primitive Count Geneva 2005 663.2 Mio 24.8 M-Points Geneva 2009 1.2 Gio 46.7 M-Points Geneva 2013 3.9 Gio 4.2 G-Points Geneva 2017 7.0 Gio 7.5 G-Points The color of the models corresponds to the points classification. In addition, the models have a density that considerably increases with time, from 1 points/m^2 (2005) to 25 points/m^2 (2017). This disparity of density is considered as part of the sampling disparity, leading to a set of data very interesting to analyze and benchmark the differences detection algorithm.","title":"Point-Based Models : LIDAR"},{"location":"TASK-DIFF/#models-statistical-analysis_1","text":"As for line and triangle-based models, a statistical analysis of the point-based models is performed. The analysis consists in computing an approximation of the nearest neighbor distance distribution of points. The following figure shows the distribution of the 2005 and 2009 models : Statistical analysis : Nearest neighbor distribution approximation of the 2005 (left) and 2009 (right) models and the following figure shows the results for the 2013 and 2017 models : Statistical analysis : Nearest neighbor distribution approximation of the 2013 (left) and 2017 (right) models The nearest neighbor distribution tends to go toward zeros with the year of acquisition, showing that modern models are significantly denser that the older ones, making these data-sets interesting for the differences detection algorithm analysis.","title":"Models : Statistical Analysis"},{"location":"TASK-DIFF/#differences-detection-algorithm-direct-application-on-point-based-models","text":"In order to determine the performances of the differences detection algorithm on the selected point-based models, the algorithm is simply applied without any adaptation on the data-sets and the results are analyzed. The following images give an overview of the obtained results comparing the 2005 and 2009 models : Application of the differences detection algorithm on point-based models : Geneva model of 2005 and 2009 with 2005 as primary (left) and inversely (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution One can see that the obtained results are very similar to the results obtained with the previously implemented XOR logical operator. The only differences is that the identical points are shown (in dark gray) along with the highlighted points (showing the differences). The same conclusion applies : the obtained composed model is difficult to read as it is dominated by sampling disparities. One can, by carefully looking at the model, ending up detecting large modifications by searching for highlighted points accumulation. In addition, taking one model or the other as primary for the algorithm does not really help as shown on the images above. The same conclusion applies even when the two compared models comes with a similar point density as the 2013 and 2017 models : Application of the differences detection algorithm on point-based models : Geneva model of 2013 and 2017 with 2013 as primary (left) and inversely (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution One can nevertheless observe that choosing the less dense model as primary leads to results a bit more clear for differences detection, but remaining very hard to interpret for a user, and much more for automated processes. In addition, the performances of the algorithm are very poor as point-based models are much denser in terms of primitives than line or triangle-based models. These reasons lead to the conclusion that the algorithm can not be directly used for point-based models and need a more specific approach.","title":"Differences Detection Algorithm : Direct Application on Point-Based Models"},{"location":"TASK-DIFF/#differences-detection-algorithm-adaptation-for-point-based-models","text":"In order to adapt the differences detection algorithm for point-based models, two aspects have to be addressed : the efficiency of the detection (server-side) and the reduction of the sampling disparities over-representation. The problem of efficiency can be solved quite easily if the adaptation of the differences detection algorithm goes in the direction of logical operators, for which an efficient methodology is already implemented. Solving the sampling disparity over-representation is more complicated. The adopted solution is inspired from a simple observation : the less deep (density of cells) the queries are, the clearer the obtained representation is. This can be illustrated by the following images showing the 2005 model compared with the 2009 one with depth equal to 7, 6 and 5, from left to right : Example of decreasing query depth on the comparison of 2005 and 2009 models - Data SITG Right-click on the image and select \"View Image\" for full resolution This is expected, as the sampling disparities can only appear at scales corresponding to the nearest neighbor distribution. Nevertheless, as the depth is decreased, the models become less and less dense. The increase of differences readability is then compensated by the lack of density, making the structures more difficult to identify, and then, their subsequent modifications. The goal of the algorithm adaptation is to keep both readability and density. To achieve this goal, the implementation of the previous XOR operator is considered as a base, mostly for its efficiency. As the XOR simply detects if a cell of the space-time discretization at a given time is in a different state as its counterpart at another time, it can be modulated to introduce a scale delay mechanism that only applies detection on low-valued scales, broadcasting their results to their daughter cells. This allows to preserve the density and to perform the detection only on sufficiently shallow scales to avoid sampling disparities to become dominant. The question is how to operate the scale delay according to the scale itself. Indeed, with large points of view, the delay is not necessary as the model is viewed from far away. The necessity of the scale delay appears as the point of view is reduced, and, the more it is reduced, the larger the scale delay needs to be. A scale-attached delay is then defined to associate a specific value for each depth.","title":"Differences Detection Algorithm : Adaptation for Point-Based Models"},{"location":"TASK-DIFF/#results-and-experiments_1","text":"The adaptation of the differences detection algorithm for point-based models is analyzed using the selected data-sets. An overview of its result is presented before a more formal analysis is made using differences detection made on line-based official land register data.","title":"Results and Experiments"},{"location":"TASK-DIFF/#differences-detection-overview_1","text":"Considering the two first models, from 2005 and 2009 campaigns, the following images shows the results of the initial version of the differences detection algorithm (similar to XOR operator) and its adapted version implementing the scale delay : Differences detection on 2005 and 2009 models with 2005 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution One can see how __scale delay_ is able to drastically reduce the effect of sampling disparities while comparing two point-based models. The effect is more obvious as the 2009 model is set as primary for differences detection : Differences detection on 2005 and 2009 models with 2009 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution This improvement gets more clear as the point of view is reduced. The following image shows the initial algorithm and the scale delay algorithm on a specific area of the city with 2005 as primary model : Differences detection on 2005 and 2009 models with 2005 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution By inverting the model roles and making the 2009 model primary for differences detection lead to similar results : Differences detection on 2005 and 2009 models with 2009 as primary - Left : without scale delay - Right : with scale delay - Data SITG Right-click on the image and select \"View Image\" for full resolution Considering the denser models of 2013 and 2017 campaigns, the results of the scale delay introduction also lead to a better understanding of the differences as shown on the following images : Differences detection on 2013 and 2017 models with scale delay - Left : 2013 as primary - Right : 2017 as primary - Data SITG Right-click on the image and select \"View Image\" for full resolution Nevertheless, one can see that scale delay is not able to get rid entirely of sampling disparities. The right image above, comparing the 2017 model to the 2013 one, shows sampling disparities being highlighted as differences on the wall of the building in the background. This does not affect too much the user readability, but still make the model a bit more complicated to understand. In addition, the models play an important role in the way differences can be detected through classic approach. For example, focusing on a specific building, the obtained highlighted differences : Differences detection on 2013 and 2017 models with scale delay with 2013 (left) and 2017 (right) as primary - Data SITG Right-click on the image and select \"View Image\" for full resolution could lead the user to consider the building wall as a difference. Looking at the formal situation in both 2013 and 2017 models : Structural situation in 2013 (left) and 2017 (right) - Data SITG Right-click on the image and select \"View Image\" for full resolution one can see that the detected difference comes from the missing wall on the 2013, and not from a formal evolution of the building. This example illustrates that sampling disparity is not the only factor that could reduce the readability of the model for the user.","title":"Differences Detection : Overview"},{"location":"TASK-DIFF/#differences-detection-land-register-differences-comparison","text":"Edition Note (NH) : Waiting for INTERLIS data.","title":"Differences Detection : Land Register Differences Comparison"},{"location":"TASK-DIFF/#conclusion-third-phase","text":"Edition Note (NH) : Waiting for results.","title":"Conclusion : Third Phase"},{"location":"TASK-DIFF/#conclusion","text":"Edition Note (NH) : Waiting for results.","title":"Conclusion"},{"location":"TASK-DIFF/#first-phase","text":"Edition Note (NH) : Waiting for results.","title":"First Phase"},{"location":"TASK-DIFF/#second-phase","text":"Edition Note (NH) : Waiting for results.","title":"Second Phase"},{"location":"TASK-DIFF/#third-phase","text":"Edition Note (NH) : Waiting for results.","title":"Third Phase"},{"location":"TASK-DIFF/#synthesis","text":"Edition Note (NH) : Waiting for results.","title":"Synthesis"},{"location":"TASK-DIFF/#perspectives","text":"Preliminary (NH) : Raster ingestion by the platform, opening new operators for data comparison Preliminary (NH) : Adding layers to the platform allowing to separate the data, toward more complex convolutions. Preliminary (NH) : Adding the notion of [Data Convolution Micro Language] in the platform allowing the user to build more complex convolutions with more than two source models (times). Preliminary (NH) : Attaching the platform indexation formalism to a [Swiss Box] to avoid necessity to convert all data from CH1903+/LV95 to WGS84/ellipsoidal frames. This would also allow improving communication efficiency between the server and its clients. In addition, it will also reduce the storage required by the platform and lead to a much better control of scales and cells size and shape consistency. Preliminary (NH) : Taking advantage of the differences detection algorithm on formal land register data [INTERLIS] to annotated image couples to train nets for differences detection on images and point clouds [Creation of dataset] Preliminary (NH) : The indexation, fixing the cell sizes, the poly-vertex primitive injection rules are not sufficiently clear for a simple understanding. It is required to simplify the rules in order to make automated processes more simple to fully control. This can be done with the reformulation of the indexation on the CH1903+/LV95 frame.","title":"Perspectives"},{"location":"TASK-DIFF/#codes-and-resources","text":"The following links give you access to the codes related to this task : 4D platform main framework library 4D platform front-end including graphical client and server instance Shapefile CSV export to UV3 format conversion script UV3 related tool suite including display and conversion","title":"Codes and Resources"},{"location":"TASK-DIFF/#auxiliary-developments-corrections","text":"In addition to the main developments made on the platform, some additional scripts and other corrections have been made to solve auxiliary problems or to improve the code according to the developed features during this task. The auxiliary developments are summarized here : Correction of socket read function to improve server-client connectivity. Creation of scripts that allows to insert synthetic modifications (random displacements on the vertex coordinates) on UV3 models. Creation of a script to convert CSV export from shapefile to UV3 format. The script code is available here . Adding temporary addresses (space-time index) exportation in platform 3D interface. Correction of the cell enumeration process in platform 3D interface (wrong depth limit implementation). Creation of a script allowing segmenting UV3 model according to geographical bounding box. Creation of C codes to perform statistical analysis of the point, line and triangle-based models : computation of edge size and nearest neighbor distributions. Creation of a C code allowing enumerating non-empty cell index over the Switzerland models injected in the platform. Creation of a C code allowing to automate the differences detection based on an index list and by searching in the data queried from the platform. Developments of various scripts for plots and figures creations.","title":"Auxiliary Developments &amp; Corrections"},{"location":"TASK-IDET/","text":"TASK-IDET - AM & AC \u00b6 Current Mandate Schedule : October 2020 to September 2021 (with extension options until 2024) This document describes the state and roadmap of an ongoing task (Imagery Detections - IDET) and is subject to daily revision and evolution Objective \u00b6 This task of the STDL consists of the automated analysis of geospatial images (using deep learning) while providing practical applications for specific use cases. Background and Potential Use Cases \u00b6 Swimming Pool Detector \u00b6 Label inputs for deep learning derived from cadastral data Providing a reliable detection of swimming pools allows authorities to assess the status quo to update archival datasets and to reinforce administrative construction permit processes. The status quo is based on manually digitized cadastral information. This data is used to extract feature masks which can be applied to orthophoto imagery. Deep Learning algorithms such as Faster RCNN or Mask RCNN then allow the detection of previously unregistered swimming pools in a defined perimeter (such as the Canton of Geneva). Sol AI - Solar Panel Detector \u00b6 Sol AI is a prototypical framework solution developed by the Institute Geomatics of FHNW to provide location and geometry for millions of solar panel installations in Switzerland. We programmed a big data approach using parallelized multi gpu deep learning with Pytorch and additional post-classifiers on large scale 10cm SWISSIMAGE aerial imagery datasets by swisstopo. It is shown how we found a solution to extract geometries and energy potential and how to distinguish different solar panel types. Data handling, labelling strategies, geoconversions, read/write NoSQL interfaces, as well as deep learning training and inferencing results are described. Furthermore we show challenges, sample data, optimization strategies and focus on the computational demands the large amount of data imposes. Early Detection Result of a Resnet-50 Mask-RCNN architecture The Area Statistics \u00b6 The Area Statistics of Switzerland classifies land use (LU) and land cover (LC) based on a regular 100x100m grid of 4.2 million sample points in 72 categories combined from 46 LU and 27 LC classes. The arduous manual labelling process performed by experts relies mainly on aerial imagery but also uses a catalogue of additional data to increase reliability. The goal of this study is to investigate the benefits using multimodal data from different sources and sensors using modern machine learning (ML) algorithms. Deep Convolutional Neural Networks (CNN) as well as Random Forest (RF) architectures provide automatized classification. The models are trained on aerial RGB and FCIR images, as well as auxiliary datasets such as satellite-derived time series indices and GIS data. The accurate manually annotated Area Statistics serve as conducive \u201cground truth\u201d to study the performance of ML algorithms in a challenging paradigm in particular due to the high level of detail of the LU/LC categories. Especially for underrepresented categories containing low sample counts the benefits of transfer learning were exploited by applying the CNN architecture \u201cXception\u201d independently on 50x50m RGB and FCIR orthophoto tiles. Best preliminary classification accuracies of CNN reached over 80% on individual major classes, but maximal overall accuracies threshold to 52% due to tiles with visually very similar characteristics in different smaller ground truth classes. To further improve the classification, the resulting CNN probabilities were used together with extrapolated Landsat-based index time series, digital elevation data, vegetation canopy height models and categorical cadastral information as a combined input vector for RF post-classification. The RF achieved reproducible overall accuracies of 84% for LU and 89% for LC. Certain major classes, which so far required an especially monotonous manual process, are classified with very high specific accuracies (>90%). We conclude that multimodal data as provided by sensor fusion and auxiliary data sources in a bipartite system of ML algorithms has the potential to support the expert-based classification and reduce the manual work. Therefore, the reporting period can be significantly shortened and the spatial resolution can be further increased in future. Methodology \u00b6 Environments and Frameworks \u00b6 Google Colab Google Colab as a rapid prototyping environment High-Performance Cluster at FHNW HPE Apollo 6500 with 4 NVidia V100 GPUs Pytorch Detectron2 Tensorflow COCO Data Sources \u00b6 SWISSIMAGE RGB 10cm by swisstopo SWISSIMAGE RS 10cm by swisstopo Labels drawn from the official Swiss cadastral services. The Swiss cadastral system comprises the cadastral surveying, the Cadastre of Public-law Restrictions on landownership (PLR-cadastre) and the land register. Results \u00b6 Deep Learning Benchmarking Tests \u00b6 Swimming Pool Detector \u00b6 Masks vs. Bbox with Resnet-50 Mask RCNN Resnet-50 vs. Resnet-101 Tile Size Dependencies Multi-Class Detectors \u00b6 Combining Solar Detector and Swimming Pool Detector vs. Single Class Paradigms Base Technology \u00b6 Detectron2 / Pytorch vs. Tensorflow Outlook \u00b6 Ultimately, an automatized system for surface classification based on aerial imagery and additional data sources will be proposed that allows consistent differential surface segmentation as a basis for differential change analysis. Spatiotemporal data storage provides insight into current, historical and future territorial features scalabe from small communal objects to the environmental and landscape levels. Links and Resources \u00b6 Institute Geomatics FHNW Project Area Statistics Project Sol Ai Project Animal Detection Swisstopo BFS / OFS BFE / Energiestrategie 2050","title":"TASK-IDET"},{"location":"TASK-IDET/#task-idet-am-ac","text":"Current Mandate Schedule : October 2020 to September 2021 (with extension options until 2024) This document describes the state and roadmap of an ongoing task (Imagery Detections - IDET) and is subject to daily revision and evolution","title":"TASK-IDET - AM &amp; AC"},{"location":"TASK-IDET/#objective","text":"This task of the STDL consists of the automated analysis of geospatial images (using deep learning) while providing practical applications for specific use cases.","title":"Objective"},{"location":"TASK-IDET/#background-and-potential-use-cases","text":"","title":"Background and Potential Use Cases"},{"location":"TASK-IDET/#swimming-pool-detector","text":"Label inputs for deep learning derived from cadastral data Providing a reliable detection of swimming pools allows authorities to assess the status quo to update archival datasets and to reinforce administrative construction permit processes. The status quo is based on manually digitized cadastral information. This data is used to extract feature masks which can be applied to orthophoto imagery. Deep Learning algorithms such as Faster RCNN or Mask RCNN then allow the detection of previously unregistered swimming pools in a defined perimeter (such as the Canton of Geneva).","title":"Swimming Pool Detector"},{"location":"TASK-IDET/#sol-ai-solar-panel-detector","text":"Sol AI is a prototypical framework solution developed by the Institute Geomatics of FHNW to provide location and geometry for millions of solar panel installations in Switzerland. We programmed a big data approach using parallelized multi gpu deep learning with Pytorch and additional post-classifiers on large scale 10cm SWISSIMAGE aerial imagery datasets by swisstopo. It is shown how we found a solution to extract geometries and energy potential and how to distinguish different solar panel types. Data handling, labelling strategies, geoconversions, read/write NoSQL interfaces, as well as deep learning training and inferencing results are described. Furthermore we show challenges, sample data, optimization strategies and focus on the computational demands the large amount of data imposes. Early Detection Result of a Resnet-50 Mask-RCNN architecture","title":"Sol AI - Solar Panel Detector"},{"location":"TASK-IDET/#the-area-statistics","text":"The Area Statistics of Switzerland classifies land use (LU) and land cover (LC) based on a regular 100x100m grid of 4.2 million sample points in 72 categories combined from 46 LU and 27 LC classes. The arduous manual labelling process performed by experts relies mainly on aerial imagery but also uses a catalogue of additional data to increase reliability. The goal of this study is to investigate the benefits using multimodal data from different sources and sensors using modern machine learning (ML) algorithms. Deep Convolutional Neural Networks (CNN) as well as Random Forest (RF) architectures provide automatized classification. The models are trained on aerial RGB and FCIR images, as well as auxiliary datasets such as satellite-derived time series indices and GIS data. The accurate manually annotated Area Statistics serve as conducive \u201cground truth\u201d to study the performance of ML algorithms in a challenging paradigm in particular due to the high level of detail of the LU/LC categories. Especially for underrepresented categories containing low sample counts the benefits of transfer learning were exploited by applying the CNN architecture \u201cXception\u201d independently on 50x50m RGB and FCIR orthophoto tiles. Best preliminary classification accuracies of CNN reached over 80% on individual major classes, but maximal overall accuracies threshold to 52% due to tiles with visually very similar characteristics in different smaller ground truth classes. To further improve the classification, the resulting CNN probabilities were used together with extrapolated Landsat-based index time series, digital elevation data, vegetation canopy height models and categorical cadastral information as a combined input vector for RF post-classification. The RF achieved reproducible overall accuracies of 84% for LU and 89% for LC. Certain major classes, which so far required an especially monotonous manual process, are classified with very high specific accuracies (>90%). We conclude that multimodal data as provided by sensor fusion and auxiliary data sources in a bipartite system of ML algorithms has the potential to support the expert-based classification and reduce the manual work. Therefore, the reporting period can be significantly shortened and the spatial resolution can be further increased in future.","title":"The Area Statistics"},{"location":"TASK-IDET/#methodology","text":"","title":"Methodology"},{"location":"TASK-IDET/#environments-and-frameworks","text":"Google Colab Google Colab as a rapid prototyping environment High-Performance Cluster at FHNW HPE Apollo 6500 with 4 NVidia V100 GPUs Pytorch Detectron2 Tensorflow COCO","title":"Environments and Frameworks"},{"location":"TASK-IDET/#data-sources","text":"SWISSIMAGE RGB 10cm by swisstopo SWISSIMAGE RS 10cm by swisstopo Labels drawn from the official Swiss cadastral services. The Swiss cadastral system comprises the cadastral surveying, the Cadastre of Public-law Restrictions on landownership (PLR-cadastre) and the land register.","title":"Data Sources"},{"location":"TASK-IDET/#results","text":"","title":"Results"},{"location":"TASK-IDET/#deep-learning-benchmarking-tests","text":"","title":"Deep Learning Benchmarking Tests"},{"location":"TASK-IDET/#swimming-pool-detector_1","text":"Masks vs. Bbox with Resnet-50 Mask RCNN Resnet-50 vs. Resnet-101 Tile Size Dependencies","title":"Swimming Pool Detector"},{"location":"TASK-IDET/#multi-class-detectors","text":"Combining Solar Detector and Swimming Pool Detector vs. Single Class Paradigms","title":"Multi-Class Detectors"},{"location":"TASK-IDET/#base-technology","text":"Detectron2 / Pytorch vs. Tensorflow","title":"Base Technology"},{"location":"TASK-IDET/#outlook","text":"Ultimately, an automatized system for surface classification based on aerial imagery and additional data sources will be proposed that allows consistent differential surface segmentation as a basis for differential change analysis. Spatiotemporal data storage provides insight into current, historical and future territorial features scalabe from small communal objects to the environmental and landscape levels.","title":"Outlook"},{"location":"TASK-IDET/#links-and-resources","text":"Institute Geomatics FHNW Project Area Statistics Project Sol Ai Project Animal Detection Swisstopo BFS / OFS BFE / Energiestrategie 2050","title":"Links and Resources"}]}